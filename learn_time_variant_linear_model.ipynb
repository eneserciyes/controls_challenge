{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "ACC_G = 9.81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data_path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(data_path)\n",
    "    processed_df = pd.DataFrame(\n",
    "        {\n",
    "            \"roll_lataccel\": np.sin(df[\"roll\"].values) * ACC_G,\n",
    "            \"v_ego\": df[\"vEgo\"].values,\n",
    "            \"a_ego\": df[\"aEgo\"].values,\n",
    "            \"target_lataccel\": df[\"targetLateralAcceleration\"].values,\n",
    "            \"steer_command\": -df[\n",
    "                \"steerCommand\"\n",
    "            ].values,  # steer commands are logged with left-positive convention but this simulator uses right-positive\n",
    "        }\n",
    "    )\n",
    "    return processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "for i in range(19000):\n",
    "  pd_frame = get_data(f'data/{i:05d}.csv')\n",
    "  td = pd_frame[:100].values\n",
    "  train_data.append(td)\n",
    "\n",
    "train_data = np.array(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = []\n",
    "for i in range(19000, 20000):\n",
    "  pd_frame = get_data(f'data/{i:05d}.csv')\n",
    "  td = pd_frame[:100].values\n",
    "  val_data.append(td)\n",
    "\n",
    "val_data = np.array(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = len(train_data) # train_data.shape[0]\n",
    "\n",
    "Xtr = torch.tensor(train_data[:data_size], dtype=torch.float32)# .reshape(-1, 5)\n",
    "Xval = torch.tensor(val_data, dtype=torch.float32)# .reshape(-1, 5)\n",
    "\n",
    "mean, std = Xtr.mean(dim=(0,1)), Xtr.std(dim=(0,1))\n",
    "\n",
    "Xtr = (Xtr - mean) / std\n",
    "Xval = (Xval - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytr = (Xtr[:, 1:, 3:4] - Xtr[:, :-1, 3:4]) # delta lateral acceleration\n",
    "Yval = (Xval[:, 1:, 3:4] - Xval[:, :-1, 3:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr = Xtr[:, :-1].reshape(-1, 5)\n",
    "Xval = Xval[:, :-1].reshape(-1, 5)\n",
    "\n",
    "Ytr = Ytr.reshape(-1)\n",
    "Yval = Yval.reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.9169,  1.1152, -0.1009,  1.7394,  1.5623]), tensor(0.0804))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr[0], Ytr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.8997,  1.1145, -0.1498,  1.8198,  1.5829])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(Xtr, Ytr, batch_size: int):\n",
    "    idx = np.random.choice(Xtr.shape[0], batch_size)\n",
    "    return Xtr[idx], Ytr[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LTVDynamicsModel(nn.Module):  # Linear Time-Varying Dynamics Model\n",
    "    def __init__(self, layers=[64, 64]):\n",
    "        super(LTVDynamicsModel, self).__init__()\n",
    "        layers = [nn.Linear(3, layers[0]), nn.ReLU()] + [\n",
    "            nn.Linear(layers[i], layers[i + 1]) for i in range(len(layers) - 1)\n",
    "        ] + [nn.Linear(layers[-1], 3)]\n",
    "        self.time_varying_F = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, xu):\n",
    "        \"\"\"\n",
    "        xu: [roll_lataccel, v_ego, a_ego, lataccel, steer_command]\n",
    "        \"\"\"\n",
    "        x = self.time_varying_F(xu[:, :3]) # Ft(roll_lataccel, v_ego, a_ego)\n",
    "        Ft = x[:, 0:2].reshape(-1, 1, 2)\n",
    "        ft = x[:, 2:].reshape(-1, 1, 1)\n",
    "\n",
    "        xt = xu[:, 3:].reshape(-1, 2, 1) # [x, u]\n",
    "        xt1 = (torch.bmm(Ft, xt) + ft).reshape(-1) # [x_t+1]\n",
    "        return xt1\n",
    "\n",
    "model = LTVDynamicsModel([128, 128, 128, 128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "model.cuda()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss = float('inf')\n",
    "best_train_loss = float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.lr = 1e-5\n",
    "num_steps = 100000\n",
    "batch_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Validation Loss 0.04104582592844963\n",
      "Step 0: Train Loss 0.017528023570775986 | Best Val Loss 0.04104582592844963\n",
      "Step 100: Train Loss 0.0025981850922107697 | Best Val Loss 0.04104582592844963\n",
      "Step 200: Train Loss 0.008357249200344086 | Best Val Loss 0.04104582592844963\n",
      "Step 300: Train Loss 0.01295576710253954 | Best Val Loss 0.04104582592844963\n",
      "Step 400: Train Loss 0.005972393322736025 | Best Val Loss 0.04104582592844963\n",
      "Step 500: Train Loss 0.004852834157645702 | Best Val Loss 0.04104582592844963\n",
      "Step 600: Train Loss 0.004040725063532591 | Best Val Loss 0.04104582592844963\n",
      "Step 700: Train Loss 0.004120287485420704 | Best Val Loss 0.04104582592844963\n",
      "Step 800: Train Loss 0.01531993504613638 | Best Val Loss 0.04104582592844963\n",
      "Step 900: Train Loss 0.1145501434803009 | Best Val Loss 0.04104582592844963\n",
      "Step 1000: Validation Loss 0.38088127970695496\n",
      "Step 1000: Train Loss 0.5004541873931885 | Best Val Loss 0.04104582592844963\n",
      "Step 1100: Train Loss 0.03650283068418503 | Best Val Loss 0.04104582592844963\n",
      "Step 1200: Train Loss 0.013758853077888489 | Best Val Loss 0.04104582592844963\n",
      "Step 1300: Train Loss 0.082094706594944 | Best Val Loss 0.04104582592844963\n",
      "Step 1400: Train Loss 0.14244362711906433 | Best Val Loss 0.04104582592844963\n",
      "Step 1500: Train Loss 0.011007556691765785 | Best Val Loss 0.04104582592844963\n",
      "Step 1600: Train Loss 0.06322509795427322 | Best Val Loss 0.04104582592844963\n",
      "Step 1700: Train Loss 0.01162634789943695 | Best Val Loss 0.04104582592844963\n",
      "Step 1800: Train Loss 0.010205674916505814 | Best Val Loss 0.04104582592844963\n",
      "Step 1900: Train Loss 4.106654644012451 | Best Val Loss 0.04104582592844963\n",
      "Step 2000: Validation Loss 0.025055356323719025\n",
      "Step 2000: Train Loss 0.011478414759039879 | Best Val Loss 0.025055356323719025\n",
      "Step 2100: Train Loss 0.010668089613318443 | Best Val Loss 0.025055356323719025\n",
      "Step 2200: Train Loss 0.0063537778332829475 | Best Val Loss 0.025055356323719025\n",
      "Step 2300: Train Loss 0.010738112032413483 | Best Val Loss 0.025055356323719025\n",
      "Step 2400: Train Loss 0.006941949017345905 | Best Val Loss 0.025055356323719025\n",
      "Step 2500: Train Loss 0.03207928687334061 | Best Val Loss 0.025055356323719025\n",
      "Step 2600: Train Loss 0.14254790544509888 | Best Val Loss 0.025055356323719025\n",
      "Step 2700: Train Loss 0.19567815959453583 | Best Val Loss 0.025055356323719025\n",
      "Step 2800: Train Loss 0.047477059066295624 | Best Val Loss 0.025055356323719025\n",
      "Step 2900: Train Loss 1.5976704359054565 | Best Val Loss 0.025055356323719025\n",
      "Step 3000: Validation Loss 0.08767788112163544\n",
      "Step 3000: Train Loss 0.05830153450369835 | Best Val Loss 0.025055356323719025\n",
      "Step 3100: Train Loss 0.031871430575847626 | Best Val Loss 0.025055356323719025\n",
      "Step 3200: Train Loss 0.025091316550970078 | Best Val Loss 0.025055356323719025\n",
      "Step 3300: Train Loss 0.022725626826286316 | Best Val Loss 0.025055356323719025\n",
      "Step 3400: Train Loss 0.26548904180526733 | Best Val Loss 0.025055356323719025\n",
      "Step 3500: Train Loss 0.08297836780548096 | Best Val Loss 0.025055356323719025\n",
      "Step 3600: Train Loss 0.07806357741355896 | Best Val Loss 0.025055356323719025\n",
      "Step 3700: Train Loss 0.03531075641512871 | Best Val Loss 0.025055356323719025\n",
      "Step 3800: Train Loss 0.45609050989151 | Best Val Loss 0.025055356323719025\n",
      "Step 3900: Train Loss 0.09070727974176407 | Best Val Loss 0.025055356323719025\n",
      "Step 4000: Validation Loss 0.07235077023506165\n",
      "Step 4000: Train Loss 0.05235803872346878 | Best Val Loss 0.025055356323719025\n",
      "Step 4100: Train Loss 0.3700176477432251 | Best Val Loss 0.025055356323719025\n",
      "Step 4200: Train Loss 0.035418715327978134 | Best Val Loss 0.025055356323719025\n",
      "Step 4300: Train Loss 0.026839755475521088 | Best Val Loss 0.025055356323719025\n",
      "Step 4400: Train Loss 0.013462742790579796 | Best Val Loss 0.025055356323719025\n",
      "Step 4500: Train Loss 0.015704449266195297 | Best Val Loss 0.025055356323719025\n",
      "Step 4600: Train Loss 0.011333928443491459 | Best Val Loss 0.025055356323719025\n",
      "Step 4700: Train Loss 0.14582036435604095 | Best Val Loss 0.025055356323719025\n",
      "Step 4800: Train Loss 17.149166107177734 | Best Val Loss 0.025055356323719025\n",
      "Step 4900: Train Loss 0.027706719934940338 | Best Val Loss 0.025055356323719025\n",
      "Step 5000: Validation Loss 0.035703226923942566\n",
      "Step 5000: Train Loss 0.015089752152562141 | Best Val Loss 0.025055356323719025\n",
      "Step 5100: Train Loss 0.016822965815663338 | Best Val Loss 0.025055356323719025\n",
      "Step 5200: Train Loss 0.01267938781529665 | Best Val Loss 0.025055356323719025\n",
      "Step 5300: Train Loss 0.007669130805879831 | Best Val Loss 0.025055356323719025\n",
      "Step 5400: Train Loss 0.0931553840637207 | Best Val Loss 0.025055356323719025\n",
      "Step 5500: Train Loss 0.02600264362990856 | Best Val Loss 0.025055356323719025\n",
      "Step 5600: Train Loss 0.017586838454008102 | Best Val Loss 0.025055356323719025\n",
      "Step 5700: Train Loss 0.05375156179070473 | Best Val Loss 0.025055356323719025\n",
      "Step 5800: Train Loss 0.012231707572937012 | Best Val Loss 0.025055356323719025\n",
      "Step 5900: Train Loss 0.0469624400138855 | Best Val Loss 0.025055356323719025\n",
      "Step 6000: Validation Loss 0.038396578282117844\n",
      "Step 6000: Train Loss 0.021727129817008972 | Best Val Loss 0.025055356323719025\n",
      "Step 6100: Train Loss 0.6986973881721497 | Best Val Loss 0.025055356323719025\n",
      "Step 6200: Train Loss 0.07248666882514954 | Best Val Loss 0.025055356323719025\n",
      "Step 6300: Train Loss 0.032183971256017685 | Best Val Loss 0.025055356323719025\n",
      "Step 6400: Train Loss 0.024402834475040436 | Best Val Loss 0.025055356323719025\n",
      "Step 6500: Train Loss 0.01551427599042654 | Best Val Loss 0.025055356323719025\n",
      "Step 6600: Train Loss 0.2203119695186615 | Best Val Loss 0.025055356323719025\n",
      "Step 6700: Train Loss 0.03903644531965256 | Best Val Loss 0.025055356323719025\n",
      "Step 6800: Train Loss 0.0319092683494091 | Best Val Loss 0.025055356323719025\n",
      "Step 6900: Train Loss 0.017371390014886856 | Best Val Loss 0.025055356323719025\n",
      "Step 7000: Validation Loss 0.202022522687912\n",
      "Step 7000: Train Loss 0.19406768679618835 | Best Val Loss 0.025055356323719025\n",
      "Step 7100: Train Loss 0.03582232445478439 | Best Val Loss 0.025055356323719025\n",
      "Step 7200: Train Loss 0.022416094318032265 | Best Val Loss 0.025055356323719025\n",
      "Step 7300: Train Loss 0.020924922078847885 | Best Val Loss 0.025055356323719025\n",
      "Step 7400: Train Loss 0.022286083549261093 | Best Val Loss 0.025055356323719025\n",
      "Step 7500: Train Loss 0.012246929109096527 | Best Val Loss 0.025055356323719025\n",
      "Step 7600: Train Loss 0.012388947419822216 | Best Val Loss 0.025055356323719025\n",
      "Step 7700: Train Loss 0.011369070038199425 | Best Val Loss 0.025055356323719025\n",
      "Step 7800: Train Loss 0.009036998264491558 | Best Val Loss 0.025055356323719025\n",
      "Step 7900: Train Loss 0.04494428634643555 | Best Val Loss 0.025055356323719025\n",
      "Step 8000: Validation Loss 0.03471964970231056\n",
      "Step 8000: Train Loss 0.012157706543803215 | Best Val Loss 0.025055356323719025\n",
      "Step 8100: Train Loss 0.019587257876992226 | Best Val Loss 0.025055356323719025\n",
      "Step 8200: Train Loss 0.5510162115097046 | Best Val Loss 0.025055356323719025\n",
      "Step 8300: Train Loss 0.10840906202793121 | Best Val Loss 0.025055356323719025\n",
      "Step 8400: Train Loss 0.020169368013739586 | Best Val Loss 0.025055356323719025\n",
      "Step 8500: Train Loss 0.014866922050714493 | Best Val Loss 0.025055356323719025\n",
      "Step 8600: Train Loss 0.012820886448025703 | Best Val Loss 0.025055356323719025\n",
      "Step 8700: Train Loss 0.011108700186014175 | Best Val Loss 0.025055356323719025\n",
      "Step 8800: Train Loss 0.21504724025726318 | Best Val Loss 0.025055356323719025\n",
      "Step 8900: Train Loss 0.011391634121537209 | Best Val Loss 0.025055356323719025\n",
      "Step 9000: Validation Loss 0.04225977137684822\n",
      "Step 9000: Train Loss 0.011989718303084373 | Best Val Loss 0.025055356323719025\n",
      "Step 9100: Train Loss 0.010281173512339592 | Best Val Loss 0.025055356323719025\n",
      "Step 9200: Train Loss 0.029139354825019836 | Best Val Loss 0.025055356323719025\n",
      "Step 9300: Train Loss 0.013968799263238907 | Best Val Loss 0.025055356323719025\n",
      "Step 9400: Train Loss 0.012347666546702385 | Best Val Loss 0.025055356323719025\n",
      "Step 9500: Train Loss 0.014980507083237171 | Best Val Loss 0.025055356323719025\n",
      "Step 9600: Train Loss 0.007872012443840504 | Best Val Loss 0.025055356323719025\n",
      "Step 9700: Train Loss 0.006975729018449783 | Best Val Loss 0.025055356323719025\n",
      "Step 9800: Train Loss 0.016684766858816147 | Best Val Loss 0.025055356323719025\n",
      "Step 9900: Train Loss 0.009697954170405865 | Best Val Loss 0.025055356323719025\n",
      "Step 10000: Validation Loss 0.02944488264620304\n",
      "Step 10000: Train Loss 0.006424586288630962 | Best Val Loss 0.025055356323719025\n",
      "Step 10100: Train Loss 0.0301508828997612 | Best Val Loss 0.025055356323719025\n",
      "Step 10200: Train Loss 0.0109489094465971 | Best Val Loss 0.025055356323719025\n",
      "Step 10300: Train Loss 0.01032988354563713 | Best Val Loss 0.025055356323719025\n",
      "Step 10400: Train Loss 0.006708200555294752 | Best Val Loss 0.025055356323719025\n",
      "Step 10500: Train Loss 0.008718583732843399 | Best Val Loss 0.025055356323719025\n",
      "Step 10600: Train Loss 0.006821125745773315 | Best Val Loss 0.025055356323719025\n",
      "Step 10700: Train Loss 0.042027805000543594 | Best Val Loss 0.025055356323719025\n",
      "Step 10800: Train Loss 0.02463637664914131 | Best Val Loss 0.025055356323719025\n",
      "Step 10900: Train Loss 0.008259481750428677 | Best Val Loss 0.025055356323719025\n",
      "Step 11000: Validation Loss 0.025002142414450645\n",
      "Step 11000: Train Loss 0.005852373316884041 | Best Val Loss 0.025002142414450645\n",
      "Step 11100: Train Loss 0.2512432932853699 | Best Val Loss 0.025002142414450645\n",
      "Step 11200: Train Loss 0.018016107380390167 | Best Val Loss 0.025002142414450645\n",
      "Step 11300: Train Loss 0.008551409468054771 | Best Val Loss 0.025002142414450645\n",
      "Step 11400: Train Loss 0.007514341734349728 | Best Val Loss 0.025002142414450645\n",
      "Step 11500: Train Loss 0.023896511644124985 | Best Val Loss 0.025002142414450645\n",
      "Step 11600: Train Loss 0.03717966750264168 | Best Val Loss 0.025002142414450645\n",
      "Step 11700: Train Loss 0.011952325701713562 | Best Val Loss 0.025002142414450645\n",
      "Step 11800: Train Loss 0.011869573965668678 | Best Val Loss 0.025002142414450645\n",
      "Step 11900: Train Loss 0.04027663543820381 | Best Val Loss 0.025002142414450645\n",
      "Step 12000: Validation Loss 0.3537745475769043\n",
      "Step 12000: Train Loss 0.34486842155456543 | Best Val Loss 0.025002142414450645\n",
      "Step 12100: Train Loss 0.0398632250726223 | Best Val Loss 0.025002142414450645\n",
      "Step 12200: Train Loss 0.016467168927192688 | Best Val Loss 0.025002142414450645\n",
      "Step 12300: Train Loss 0.014877818524837494 | Best Val Loss 0.025002142414450645\n",
      "Step 12400: Train Loss 0.01268710009753704 | Best Val Loss 0.025002142414450645\n",
      "Step 12500: Train Loss 0.021257122978568077 | Best Val Loss 0.025002142414450645\n",
      "Step 12600: Train Loss 0.013815408572554588 | Best Val Loss 0.025002142414450645\n",
      "Step 12700: Train Loss 0.02528364025056362 | Best Val Loss 0.025002142414450645\n",
      "Step 12800: Train Loss 0.3532761335372925 | Best Val Loss 0.025002142414450645\n",
      "Step 12900: Train Loss 0.6183350086212158 | Best Val Loss 0.025002142414450645\n",
      "Step 13000: Validation Loss 0.08982748538255692\n",
      "Step 13000: Train Loss 0.06375676393508911 | Best Val Loss 0.025002142414450645\n",
      "Step 13100: Train Loss 0.014648610725998878 | Best Val Loss 0.025002142414450645\n",
      "Step 13200: Train Loss 0.010879840701818466 | Best Val Loss 0.025002142414450645\n",
      "Step 13300: Train Loss 0.005743090994656086 | Best Val Loss 0.025002142414450645\n",
      "Step 13400: Train Loss 0.009109382517635822 | Best Val Loss 0.025002142414450645\n",
      "Step 13500: Train Loss 0.005526430439203978 | Best Val Loss 0.025002142414450645\n",
      "Step 13600: Train Loss 0.008316975086927414 | Best Val Loss 0.025002142414450645\n",
      "Step 13700: Train Loss 0.10519947856664658 | Best Val Loss 0.025002142414450645\n",
      "Step 13800: Train Loss 0.01634776033461094 | Best Val Loss 0.025002142414450645\n",
      "Step 13900: Train Loss 0.045023977756500244 | Best Val Loss 0.025002142414450645\n",
      "Step 14000: Validation Loss 0.031173525378108025\n",
      "Step 14000: Train Loss 0.017402304336428642 | Best Val Loss 0.025002142414450645\n",
      "Step 14100: Train Loss 0.13560894131660461 | Best Val Loss 0.025002142414450645\n",
      "Step 14200: Train Loss 0.10467210412025452 | Best Val Loss 0.025002142414450645\n",
      "Step 14300: Train Loss 0.039323292672634125 | Best Val Loss 0.025002142414450645\n",
      "Step 14400: Train Loss 0.02855575643479824 | Best Val Loss 0.025002142414450645\n",
      "Step 14500: Train Loss 0.040678489953279495 | Best Val Loss 0.025002142414450645\n",
      "Step 14600: Train Loss 0.013737000524997711 | Best Val Loss 0.025002142414450645\n",
      "Step 14700: Train Loss 0.019910402595996857 | Best Val Loss 0.025002142414450645\n",
      "Step 14800: Train Loss 0.012333463877439499 | Best Val Loss 0.025002142414450645\n",
      "Step 14900: Train Loss 0.30208754539489746 | Best Val Loss 0.025002142414450645\n",
      "Step 15000: Validation Loss 0.05550718680024147\n",
      "Step 15000: Train Loss 0.046256326138973236 | Best Val Loss 0.025002142414450645\n",
      "Step 15100: Train Loss 0.029257891699671745 | Best Val Loss 0.025002142414450645\n",
      "Step 15200: Train Loss 0.6922620534896851 | Best Val Loss 0.025002142414450645\n",
      "Step 15300: Train Loss 4.209918022155762 | Best Val Loss 0.025002142414450645\n",
      "Step 15400: Train Loss 2.1345582008361816 | Best Val Loss 0.025002142414450645\n",
      "Step 15500: Train Loss 0.06937675923109055 | Best Val Loss 0.025002142414450645\n",
      "Step 15600: Train Loss 0.05921822041273117 | Best Val Loss 0.025002142414450645\n",
      "Step 15700: Train Loss 0.02426471933722496 | Best Val Loss 0.025002142414450645\n",
      "Step 15800: Train Loss 0.022430233657360077 | Best Val Loss 0.025002142414450645\n",
      "Step 15900: Train Loss 0.018361739814281464 | Best Val Loss 0.025002142414450645\n",
      "Step 16000: Validation Loss 0.037180036306381226\n",
      "Step 16000: Train Loss 0.020204460248351097 | Best Val Loss 0.025002142414450645\n",
      "Step 16100: Train Loss 0.8481739163398743 | Best Val Loss 0.025002142414450645\n",
      "Step 16200: Train Loss 0.03848784789443016 | Best Val Loss 0.025002142414450645\n",
      "Step 16300: Train Loss 0.020596589893102646 | Best Val Loss 0.025002142414450645\n",
      "Step 16400: Train Loss 0.01419394463300705 | Best Val Loss 0.025002142414450645\n",
      "Step 16500: Train Loss 0.008861011825501919 | Best Val Loss 0.025002142414450645\n",
      "Step 16600: Train Loss 0.007067009806632996 | Best Val Loss 0.025002142414450645\n",
      "Step 16700: Train Loss 0.006070387549698353 | Best Val Loss 0.025002142414450645\n",
      "Step 16800: Train Loss 0.005109353922307491 | Best Val Loss 0.025002142414450645\n",
      "Step 16900: Train Loss 0.02453288435935974 | Best Val Loss 0.025002142414450645\n",
      "Step 17000: Validation Loss 0.021282896399497986\n",
      "Step 17000: Train Loss 0.009256432764232159 | Best Val Loss 0.021282896399497986\n",
      "Step 17100: Train Loss 0.04816751182079315 | Best Val Loss 0.021282896399497986\n",
      "Step 17200: Train Loss 0.0678006038069725 | Best Val Loss 0.021282896399497986\n",
      "Step 17300: Train Loss 0.017188796773552895 | Best Val Loss 0.021282896399497986\n",
      "Step 17400: Train Loss 0.013429845683276653 | Best Val Loss 0.021282896399497986\n",
      "Step 17500: Train Loss 9.367643356323242 | Best Val Loss 0.021282896399497986\n",
      "Step 17600: Train Loss 0.08017873764038086 | Best Val Loss 0.021282896399497986\n",
      "Step 17700: Train Loss 0.058657821267843246 | Best Val Loss 0.021282896399497986\n",
      "Step 17800: Train Loss 0.06938314437866211 | Best Val Loss 0.021282896399497986\n",
      "Step 17900: Train Loss 0.08270935714244843 | Best Val Loss 0.021282896399497986\n",
      "Step 18000: Validation Loss 0.03269966319203377\n",
      "Step 18000: Train Loss 0.008935827761888504 | Best Val Loss 0.021282896399497986\n",
      "Step 18100: Train Loss 0.009184490889310837 | Best Val Loss 0.021282896399497986\n",
      "Step 18200: Train Loss 0.009723635390400887 | Best Val Loss 0.021282896399497986\n",
      "Step 18300: Train Loss 0.006538393907248974 | Best Val Loss 0.021282896399497986\n",
      "Step 18400: Train Loss 0.005709312856197357 | Best Val Loss 0.021282896399497986\n",
      "Step 18500: Train Loss 0.09983888268470764 | Best Val Loss 0.021282896399497986\n",
      "Step 18600: Train Loss 0.021607084199786186 | Best Val Loss 0.021282896399497986\n",
      "Step 18700: Train Loss 0.014499553479254246 | Best Val Loss 0.021282896399497986\n",
      "Step 18800: Train Loss 0.012177947908639908 | Best Val Loss 0.021282896399497986\n",
      "Step 18900: Train Loss 0.06584256142377853 | Best Val Loss 0.021282896399497986\n",
      "Step 19000: Validation Loss 0.04180591553449631\n",
      "Step 19000: Train Loss 0.015330057591199875 | Best Val Loss 0.021282896399497986\n",
      "Step 19100: Train Loss 0.015511589124798775 | Best Val Loss 0.021282896399497986\n",
      "Step 19200: Train Loss 0.07817086577415466 | Best Val Loss 0.021282896399497986\n",
      "Step 19300: Train Loss 0.32234740257263184 | Best Val Loss 0.021282896399497986\n",
      "Step 19400: Train Loss 0.10642540454864502 | Best Val Loss 0.021282896399497986\n",
      "Step 19500: Train Loss 0.042522624135017395 | Best Val Loss 0.021282896399497986\n",
      "Step 19600: Train Loss 0.027884747833013535 | Best Val Loss 0.021282896399497986\n",
      "Step 19700: Train Loss 0.016270622611045837 | Best Val Loss 0.021282896399497986\n",
      "Step 19800: Train Loss 1.2103140354156494 | Best Val Loss 0.021282896399497986\n",
      "Step 19900: Train Loss 0.05645360052585602 | Best Val Loss 0.021282896399497986\n",
      "Step 20000: Validation Loss 0.0458003506064415\n",
      "Step 20000: Train Loss 0.03040136769413948 | Best Val Loss 0.021282896399497986\n",
      "Step 20100: Train Loss 0.06610120832920074 | Best Val Loss 0.021282896399497986\n",
      "Step 20200: Train Loss 0.03920825570821762 | Best Val Loss 0.021282896399497986\n",
      "Step 20300: Train Loss 0.0913238376379013 | Best Val Loss 0.021282896399497986\n",
      "Step 20400: Train Loss 0.22885629534721375 | Best Val Loss 0.021282896399497986\n",
      "Step 20500: Train Loss 4.548690319061279 | Best Val Loss 0.021282896399497986\n",
      "Step 20600: Train Loss 0.22897271811962128 | Best Val Loss 0.021282896399497986\n",
      "Step 20700: Train Loss 0.09974177181720734 | Best Val Loss 0.021282896399497986\n",
      "Step 20800: Train Loss 3.4140453338623047 | Best Val Loss 0.021282896399497986\n",
      "Step 20900: Train Loss 0.07498446851968765 | Best Val Loss 0.021282896399497986\n",
      "Step 21000: Validation Loss 0.06685324758291245\n",
      "Step 21000: Train Loss 0.033046893775463104 | Best Val Loss 0.021282896399497986\n",
      "Step 21100: Train Loss 0.01691976562142372 | Best Val Loss 0.021282896399497986\n",
      "Step 21200: Train Loss 0.23472806811332703 | Best Val Loss 0.021282896399497986\n",
      "Step 21300: Train Loss 0.06378281861543655 | Best Val Loss 0.021282896399497986\n",
      "Step 21400: Train Loss 0.03047063946723938 | Best Val Loss 0.021282896399497986\n",
      "Step 21500: Train Loss 0.014955919235944748 | Best Val Loss 0.021282896399497986\n",
      "Step 21600: Train Loss 0.4037479758262634 | Best Val Loss 0.021282896399497986\n",
      "Step 21700: Train Loss 0.038028784096241 | Best Val Loss 0.021282896399497986\n",
      "Step 21800: Train Loss 0.020229771733283997 | Best Val Loss 0.021282896399497986\n",
      "Step 21900: Train Loss 0.013192888349294662 | Best Val Loss 0.021282896399497986\n",
      "Step 22000: Validation Loss 0.044423989951610565\n",
      "Step 22000: Train Loss 0.013899717479944229 | Best Val Loss 0.021282896399497986\n",
      "Step 22100: Train Loss 0.011644593439996243 | Best Val Loss 0.021282896399497986\n",
      "Step 22200: Train Loss 0.011613482609391212 | Best Val Loss 0.021282896399497986\n",
      "Step 22300: Train Loss 0.8398422598838806 | Best Val Loss 0.021282896399497986\n",
      "Step 22400: Train Loss 0.15759235620498657 | Best Val Loss 0.021282896399497986\n",
      "Step 22500: Train Loss 7.712671756744385 | Best Val Loss 0.021282896399497986\n",
      "Step 22600: Train Loss 0.041576169431209564 | Best Val Loss 0.021282896399497986\n",
      "Step 22700: Train Loss 0.04147784411907196 | Best Val Loss 0.021282896399497986\n",
      "Step 22800: Train Loss 0.03605297580361366 | Best Val Loss 0.021282896399497986\n",
      "Step 22900: Train Loss 0.020738529041409492 | Best Val Loss 0.021282896399497986\n",
      "Step 23000: Validation Loss 0.03256933391094208\n",
      "Step 23000: Train Loss 0.022953789681196213 | Best Val Loss 0.021282896399497986\n",
      "Step 23100: Train Loss 0.017982345074415207 | Best Val Loss 0.021282896399497986\n",
      "Step 23200: Train Loss 0.012695002369582653 | Best Val Loss 0.021282896399497986\n",
      "Step 23300: Train Loss 0.008851995691657066 | Best Val Loss 0.021282896399497986\n",
      "Step 23400: Train Loss 0.019379928708076477 | Best Val Loss 0.021282896399497986\n",
      "Step 23500: Train Loss 0.023213408887386322 | Best Val Loss 0.021282896399497986\n",
      "Step 23600: Train Loss 0.015463890507817268 | Best Val Loss 0.021282896399497986\n",
      "Step 23700: Train Loss 0.033268895000219345 | Best Val Loss 0.021282896399497986\n",
      "Step 23800: Train Loss 0.009285885840654373 | Best Val Loss 0.021282896399497986\n",
      "Step 23900: Train Loss 0.010241301730275154 | Best Val Loss 0.021282896399497986\n",
      "Step 24000: Validation Loss 0.050611112266778946\n",
      "Step 24000: Train Loss 0.03175722062587738 | Best Val Loss 0.021282896399497986\n",
      "Step 24100: Train Loss 0.019271569326519966 | Best Val Loss 0.021282896399497986\n",
      "Step 24200: Train Loss 0.01058219000697136 | Best Val Loss 0.021282896399497986\n",
      "Step 24300: Train Loss 0.011288016103208065 | Best Val Loss 0.021282896399497986\n",
      "Step 24400: Train Loss 0.010810116305947304 | Best Val Loss 0.021282896399497986\n",
      "Step 24500: Train Loss 0.009979065507650375 | Best Val Loss 0.021282896399497986\n",
      "Step 24600: Train Loss 0.043289124965667725 | Best Val Loss 0.021282896399497986\n",
      "Step 24700: Train Loss 0.010771453380584717 | Best Val Loss 0.021282896399497986\n",
      "Step 24800: Train Loss 0.01050817221403122 | Best Val Loss 0.021282896399497986\n",
      "Step 24900: Train Loss 0.008890284225344658 | Best Val Loss 0.021282896399497986\n",
      "Step 25000: Validation Loss 0.023822925984859467\n",
      "Step 25000: Train Loss 0.008541116490960121 | Best Val Loss 0.021282896399497986\n",
      "Step 25100: Train Loss 0.024291884154081345 | Best Val Loss 0.021282896399497986\n",
      "Step 25200: Train Loss 0.016887329518795013 | Best Val Loss 0.021282896399497986\n",
      "Step 25300: Train Loss 0.01903552934527397 | Best Val Loss 0.021282896399497986\n",
      "Step 25400: Train Loss 0.018208026885986328 | Best Val Loss 0.021282896399497986\n",
      "Step 25500: Train Loss 0.011685810051858425 | Best Val Loss 0.021282896399497986\n",
      "Step 25600: Train Loss 0.012101259082555771 | Best Val Loss 0.021282896399497986\n",
      "Step 25700: Train Loss 0.00899410992860794 | Best Val Loss 0.021282896399497986\n",
      "Step 25800: Train Loss 0.0772874504327774 | Best Val Loss 0.021282896399497986\n",
      "Step 25900: Train Loss 0.027119360864162445 | Best Val Loss 0.021282896399497986\n",
      "Step 26000: Validation Loss 0.04693661257624626\n",
      "Step 26000: Train Loss 0.03395504876971245 | Best Val Loss 0.021282896399497986\n",
      "Step 26100: Train Loss 0.01754840835928917 | Best Val Loss 0.021282896399497986\n",
      "Step 26200: Train Loss 0.01926811970770359 | Best Val Loss 0.021282896399497986\n",
      "Step 26300: Train Loss 0.011149771511554718 | Best Val Loss 0.021282896399497986\n",
      "Step 26400: Train Loss 0.02794448658823967 | Best Val Loss 0.021282896399497986\n",
      "Step 26500: Train Loss 0.012195460498332977 | Best Val Loss 0.021282896399497986\n",
      "Step 26600: Train Loss 0.011085743084549904 | Best Val Loss 0.021282896399497986\n",
      "Step 26700: Train Loss 0.007278574630618095 | Best Val Loss 0.021282896399497986\n",
      "Step 26800: Train Loss 0.006286844611167908 | Best Val Loss 0.021282896399497986\n",
      "Step 26900: Train Loss 0.006485156714916229 | Best Val Loss 0.021282896399497986\n",
      "Step 27000: Validation Loss 0.022344252094626427\n",
      "Step 27000: Train Loss 0.005735907703638077 | Best Val Loss 0.021282896399497986\n",
      "Step 27100: Train Loss 0.006016368046402931 | Best Val Loss 0.021282896399497986\n",
      "Step 27200: Train Loss 0.007565597537904978 | Best Val Loss 0.021282896399497986\n",
      "Step 27300: Train Loss 0.006997975055128336 | Best Val Loss 0.021282896399497986\n",
      "Step 27400: Train Loss 0.006466131191700697 | Best Val Loss 0.021282896399497986\n",
      "Step 27500: Train Loss 0.01007632166147232 | Best Val Loss 0.021282896399497986\n",
      "Step 27600: Train Loss 0.006562720984220505 | Best Val Loss 0.021282896399497986\n",
      "Step 27700: Train Loss 0.026996038854122162 | Best Val Loss 0.021282896399497986\n",
      "Step 27800: Train Loss 2.607022762298584 | Best Val Loss 0.021282896399497986\n",
      "Step 27900: Train Loss 0.01796266809105873 | Best Val Loss 0.021282896399497986\n",
      "Step 28000: Validation Loss 0.02401319518685341\n",
      "Step 28000: Train Loss 0.010147430002689362 | Best Val Loss 0.021282896399497986\n",
      "Step 28100: Train Loss 1.0010294914245605 | Best Val Loss 0.021282896399497986\n",
      "Step 28200: Train Loss 0.007386910729110241 | Best Val Loss 0.021282896399497986\n",
      "Step 28300: Train Loss 0.0084442850202322 | Best Val Loss 0.021282896399497986\n",
      "Step 28400: Train Loss 0.022786611691117287 | Best Val Loss 0.021282896399497986\n",
      "Step 28500: Train Loss 0.0068663135170936584 | Best Val Loss 0.021282896399497986\n",
      "Step 28600: Train Loss 0.006352458149194717 | Best Val Loss 0.021282896399497986\n",
      "Step 28700: Train Loss 0.005255402065813541 | Best Val Loss 0.021282896399497986\n",
      "Step 28800: Train Loss 0.009457077831029892 | Best Val Loss 0.021282896399497986\n",
      "Step 28900: Train Loss 0.010434887371957302 | Best Val Loss 0.021282896399497986\n",
      "Step 29000: Validation Loss 0.03195264935493469\n",
      "Step 29000: Train Loss 0.01018926128745079 | Best Val Loss 0.021282896399497986\n",
      "Step 29100: Train Loss 11.710649490356445 | Best Val Loss 0.021282896399497986\n",
      "Step 29200: Train Loss 0.02266034483909607 | Best Val Loss 0.021282896399497986\n",
      "Step 29300: Train Loss 0.1553494930267334 | Best Val Loss 0.021282896399497986\n",
      "Step 29400: Train Loss 0.025693435221910477 | Best Val Loss 0.021282896399497986\n",
      "Step 29500: Train Loss 0.01514781080186367 | Best Val Loss 0.021282896399497986\n",
      "Step 29600: Train Loss 0.021478574723005295 | Best Val Loss 0.021282896399497986\n",
      "Step 29700: Train Loss 0.02266298048198223 | Best Val Loss 0.021282896399497986\n",
      "Step 29800: Train Loss 0.01246732473373413 | Best Val Loss 0.021282896399497986\n",
      "Step 29900: Train Loss 0.013801113702356815 | Best Val Loss 0.021282896399497986\n",
      "Step 30000: Validation Loss 0.048835694789886475\n",
      "Step 30000: Train Loss 0.03240694850683212 | Best Val Loss 0.021282896399497986\n",
      "Step 30100: Train Loss 0.0871453732252121 | Best Val Loss 0.021282896399497986\n",
      "Step 30200: Train Loss 0.013320374302566051 | Best Val Loss 0.021282896399497986\n",
      "Step 30300: Train Loss 0.031320326030254364 | Best Val Loss 0.021282896399497986\n",
      "Step 30400: Train Loss 0.25224050879478455 | Best Val Loss 0.021282896399497986\n",
      "Step 30500: Train Loss 0.23932164907455444 | Best Val Loss 0.021282896399497986\n",
      "Step 30600: Train Loss 1.4823811054229736 | Best Val Loss 0.021282896399497986\n",
      "Step 30700: Train Loss 0.07566404342651367 | Best Val Loss 0.021282896399497986\n",
      "Step 30800: Train Loss 0.028098227456212044 | Best Val Loss 0.021282896399497986\n",
      "Step 30900: Train Loss 0.019109955057501793 | Best Val Loss 0.021282896399497986\n",
      "Step 31000: Validation Loss 0.037042345851659775\n",
      "Step 31000: Train Loss 0.02454800345003605 | Best Val Loss 0.021282896399497986\n",
      "Step 31100: Train Loss 0.03610728681087494 | Best Val Loss 0.021282896399497986\n",
      "Step 31200: Train Loss 0.07592413574457169 | Best Val Loss 0.021282896399497986\n",
      "Step 31300: Train Loss 0.021622033789753914 | Best Val Loss 0.021282896399497986\n",
      "Step 31400: Train Loss 0.31973177194595337 | Best Val Loss 0.021282896399497986\n",
      "Step 31500: Train Loss 0.0570700503885746 | Best Val Loss 0.021282896399497986\n",
      "Step 31600: Train Loss 5.32921838760376 | Best Val Loss 0.021282896399497986\n",
      "Step 31700: Train Loss 0.017639532685279846 | Best Val Loss 0.021282896399497986\n",
      "Step 31800: Train Loss 0.01649564877152443 | Best Val Loss 0.021282896399497986\n",
      "Step 31900: Train Loss 0.01430978998541832 | Best Val Loss 0.021282896399497986\n",
      "Step 32000: Validation Loss 0.255174458026886\n",
      "Step 32000: Train Loss 0.12951505184173584 | Best Val Loss 0.021282896399497986\n",
      "Step 32100: Train Loss 0.08271211385726929 | Best Val Loss 0.021282896399497986\n",
      "Step 32200: Train Loss 0.04074252024292946 | Best Val Loss 0.021282896399497986\n",
      "Step 32300: Train Loss 0.028916478157043457 | Best Val Loss 0.021282896399497986\n",
      "Step 32400: Train Loss 0.05268368124961853 | Best Val Loss 0.021282896399497986\n",
      "Step 32500: Train Loss 0.028178203850984573 | Best Val Loss 0.021282896399497986\n",
      "Step 32600: Train Loss 0.03325043246150017 | Best Val Loss 0.021282896399497986\n",
      "Step 32700: Train Loss 0.06438755989074707 | Best Val Loss 0.021282896399497986\n",
      "Step 32800: Train Loss 0.02621525339782238 | Best Val Loss 0.021282896399497986\n",
      "Step 32900: Train Loss 0.020827623084187508 | Best Val Loss 0.021282896399497986\n",
      "Step 33000: Validation Loss 0.055591732263565063\n",
      "Step 33000: Train Loss 0.028038766235113144 | Best Val Loss 0.021282896399497986\n",
      "Step 33100: Train Loss 0.028344519436359406 | Best Val Loss 0.021282896399497986\n",
      "Step 33200: Train Loss 0.012925984337925911 | Best Val Loss 0.021282896399497986\n",
      "Step 33300: Train Loss 0.013921458274126053 | Best Val Loss 0.021282896399497986\n",
      "Step 33400: Train Loss 0.2625945508480072 | Best Val Loss 0.021282896399497986\n",
      "Step 33500: Train Loss 0.022810697555541992 | Best Val Loss 0.021282896399497986\n",
      "Step 33600: Train Loss 0.0751284807920456 | Best Val Loss 0.021282896399497986\n",
      "Step 33700: Train Loss 0.13919752836227417 | Best Val Loss 0.021282896399497986\n",
      "Step 33800: Train Loss 10.609092712402344 | Best Val Loss 0.021282896399497986\n",
      "Step 33900: Train Loss 0.26051005721092224 | Best Val Loss 0.021282896399497986\n",
      "Step 34000: Validation Loss 0.4037642478942871\n",
      "Step 34000: Train Loss 0.2407374233007431 | Best Val Loss 0.021282896399497986\n",
      "Step 34100: Train Loss 0.08316149562597275 | Best Val Loss 0.021282896399497986\n",
      "Step 34200: Train Loss 0.05231041461229324 | Best Val Loss 0.021282896399497986\n",
      "Step 34300: Train Loss 0.028140682727098465 | Best Val Loss 0.021282896399497986\n",
      "Step 34400: Train Loss 0.028408240526914597 | Best Val Loss 0.021282896399497986\n",
      "Step 34500: Train Loss 0.017515011131763458 | Best Val Loss 0.021282896399497986\n",
      "Step 34600: Train Loss 0.0210625808686018 | Best Val Loss 0.021282896399497986\n",
      "Step 34700: Train Loss 1.0890278816223145 | Best Val Loss 0.021282896399497986\n",
      "Step 34800: Train Loss 0.09476268291473389 | Best Val Loss 0.021282896399497986\n",
      "Step 34900: Train Loss 0.06160438433289528 | Best Val Loss 0.021282896399497986\n",
      "Step 35000: Validation Loss 0.8729119300842285\n",
      "Step 35000: Train Loss 0.6249163150787354 | Best Val Loss 0.021282896399497986\n",
      "Step 35100: Train Loss 0.12017011642456055 | Best Val Loss 0.021282896399497986\n",
      "Step 35200: Train Loss 0.04946473240852356 | Best Val Loss 0.021282896399497986\n",
      "Step 35300: Train Loss 0.34462136030197144 | Best Val Loss 0.021282896399497986\n",
      "Step 35400: Train Loss 0.13637760281562805 | Best Val Loss 0.021282896399497986\n",
      "Step 35500: Train Loss 0.05751548707485199 | Best Val Loss 0.021282896399497986\n",
      "Step 35600: Train Loss 0.04841490834951401 | Best Val Loss 0.021282896399497986\n",
      "Step 35700: Train Loss 0.024005070328712463 | Best Val Loss 0.021282896399497986\n",
      "Step 35800: Train Loss 0.015679191797971725 | Best Val Loss 0.021282896399497986\n",
      "Step 35900: Train Loss 0.014643372967839241 | Best Val Loss 0.021282896399497986\n",
      "Step 36000: Validation Loss 0.030621683225035667\n",
      "Step 36000: Train Loss 0.012735020369291306 | Best Val Loss 0.021282896399497986\n",
      "Step 36100: Train Loss 0.011974598281085491 | Best Val Loss 0.021282896399497986\n",
      "Step 36200: Train Loss 0.02547628805041313 | Best Val Loss 0.021282896399497986\n",
      "Step 36300: Train Loss 0.010050765238702297 | Best Val Loss 0.021282896399497986\n",
      "Step 36400: Train Loss 0.010352295823395252 | Best Val Loss 0.021282896399497986\n",
      "Step 36500: Train Loss 0.008864195086061954 | Best Val Loss 0.021282896399497986\n",
      "Step 36600: Train Loss 0.011788790114223957 | Best Val Loss 0.021282896399497986\n",
      "Step 36700: Train Loss 0.009889182634651661 | Best Val Loss 0.021282896399497986\n",
      "Step 36800: Train Loss 0.008289827033877373 | Best Val Loss 0.021282896399497986\n",
      "Step 36900: Train Loss 0.009546194225549698 | Best Val Loss 0.021282896399497986\n",
      "Step 37000: Validation Loss 0.1359660029411316\n",
      "Step 37000: Train Loss 0.09574252367019653 | Best Val Loss 0.021282896399497986\n",
      "Step 37100: Train Loss 0.028352588415145874 | Best Val Loss 0.021282896399497986\n",
      "Step 37200: Train Loss 0.027365610003471375 | Best Val Loss 0.021282896399497986\n",
      "Step 37300: Train Loss 0.021167170256376266 | Best Val Loss 0.021282896399497986\n",
      "Step 37400: Train Loss 0.016210392117500305 | Best Val Loss 0.021282896399497986\n",
      "Step 37500: Train Loss 0.08839866518974304 | Best Val Loss 0.021282896399497986\n",
      "Step 37600: Train Loss 0.023197222501039505 | Best Val Loss 0.021282896399497986\n",
      "Step 37700: Train Loss 0.016704216599464417 | Best Val Loss 0.021282896399497986\n",
      "Step 37800: Train Loss 0.01444663293659687 | Best Val Loss 0.021282896399497986\n",
      "Step 37900: Train Loss 0.014870144426822662 | Best Val Loss 0.021282896399497986\n",
      "Step 38000: Validation Loss 0.06028752401471138\n",
      "Step 38000: Train Loss 0.037416208535432816 | Best Val Loss 0.021282896399497986\n",
      "Step 38100: Train Loss 0.01809697411954403 | Best Val Loss 0.021282896399497986\n",
      "Step 38200: Train Loss 0.01707710698246956 | Best Val Loss 0.021282896399497986\n",
      "Step 38300: Train Loss 0.09259191155433655 | Best Val Loss 0.021282896399497986\n",
      "Step 38400: Train Loss 0.12980307638645172 | Best Val Loss 0.021282896399497986\n",
      "Step 38500: Train Loss 0.02965756505727768 | Best Val Loss 0.021282896399497986\n",
      "Step 38600: Train Loss 0.02148035541176796 | Best Val Loss 0.021282896399497986\n",
      "Step 38700: Train Loss 0.013550475239753723 | Best Val Loss 0.021282896399497986\n",
      "Step 38800: Train Loss 0.11725323647260666 | Best Val Loss 0.021282896399497986\n",
      "Step 38900: Train Loss 0.09356799721717834 | Best Val Loss 0.021282896399497986\n",
      "Step 39000: Validation Loss 0.16981691122055054\n",
      "Step 39000: Train Loss 0.14160968363285065 | Best Val Loss 0.021282896399497986\n",
      "Step 39100: Train Loss 0.34126877784729004 | Best Val Loss 0.021282896399497986\n",
      "Step 39200: Train Loss 0.44493719935417175 | Best Val Loss 0.021282896399497986\n",
      "Step 39300: Train Loss 0.05317825451493263 | Best Val Loss 0.021282896399497986\n",
      "Step 39400: Train Loss 0.5100094676017761 | Best Val Loss 0.021282896399497986\n",
      "Step 39500: Train Loss 0.04183146357536316 | Best Val Loss 0.021282896399497986\n",
      "Step 39600: Train Loss 0.5066026449203491 | Best Val Loss 0.021282896399497986\n",
      "Step 39700: Train Loss 0.13640189170837402 | Best Val Loss 0.021282896399497986\n",
      "Step 39800: Train Loss 0.11513420939445496 | Best Val Loss 0.021282896399497986\n",
      "Step 39900: Train Loss 0.10528865456581116 | Best Val Loss 0.021282896399497986\n",
      "Step 40000: Validation Loss 0.1437779664993286\n",
      "Step 40000: Train Loss 0.07834584265947342 | Best Val Loss 0.021282896399497986\n",
      "Step 40100: Train Loss 0.09690269827842712 | Best Val Loss 0.021282896399497986\n",
      "Step 40200: Train Loss 0.08115912973880768 | Best Val Loss 0.021282896399497986\n",
      "Step 40300: Train Loss 0.06982535123825073 | Best Val Loss 0.021282896399497986\n",
      "Step 40400: Train Loss 0.061596423387527466 | Best Val Loss 0.021282896399497986\n",
      "Step 40500: Train Loss 0.19363290071487427 | Best Val Loss 0.021282896399497986\n",
      "Step 40600: Train Loss 0.6704332232475281 | Best Val Loss 0.021282896399497986\n",
      "Step 40700: Train Loss 0.14220182597637177 | Best Val Loss 0.021282896399497986\n",
      "Step 40800: Train Loss 0.13184446096420288 | Best Val Loss 0.021282896399497986\n",
      "Step 40900: Train Loss 0.05570506304502487 | Best Val Loss 0.021282896399497986\n",
      "Step 41000: Validation Loss 0.2829206585884094\n",
      "Step 41000: Train Loss 0.19282864034175873 | Best Val Loss 0.021282896399497986\n",
      "Step 41100: Train Loss 2.4019670486450195 | Best Val Loss 0.021282896399497986\n",
      "Step 41200: Train Loss 0.19809025526046753 | Best Val Loss 0.021282896399497986\n",
      "Step 41300: Train Loss 0.06726045161485672 | Best Val Loss 0.021282896399497986\n",
      "Step 41400: Train Loss 24.779361724853516 | Best Val Loss 0.021282896399497986\n",
      "Step 41500: Train Loss 1.2297091484069824 | Best Val Loss 0.021282896399497986\n",
      "Step 41600: Train Loss 0.6068097352981567 | Best Val Loss 0.021282896399497986\n",
      "Step 41700: Train Loss 0.527174174785614 | Best Val Loss 0.021282896399497986\n",
      "Step 41800: Train Loss 0.2885512113571167 | Best Val Loss 0.021282896399497986\n",
      "Step 41900: Train Loss 0.32780393958091736 | Best Val Loss 0.021282896399497986\n",
      "Step 42000: Validation Loss 0.22318996489048004\n",
      "Step 42000: Train Loss 0.2313087433576584 | Best Val Loss 0.021282896399497986\n",
      "Step 42100: Train Loss 0.1794804185628891 | Best Val Loss 0.021282896399497986\n",
      "Step 42200: Train Loss 0.3863627314567566 | Best Val Loss 0.021282896399497986\n",
      "Step 42300: Train Loss 0.2312382310628891 | Best Val Loss 0.021282896399497986\n",
      "Step 42400: Train Loss 0.17266038060188293 | Best Val Loss 0.021282896399497986\n",
      "Step 42500: Train Loss 0.10671892762184143 | Best Val Loss 0.021282896399497986\n",
      "Step 42600: Train Loss 0.11254630982875824 | Best Val Loss 0.021282896399497986\n",
      "Step 42700: Train Loss 0.08774061501026154 | Best Val Loss 0.021282896399497986\n",
      "Step 42800: Train Loss 0.22082599997520447 | Best Val Loss 0.021282896399497986\n",
      "Step 42900: Train Loss 0.10304269194602966 | Best Val Loss 0.021282896399497986\n",
      "Step 43000: Validation Loss 0.10734031349420547\n",
      "Step 43000: Train Loss 0.10529792308807373 | Best Val Loss 0.021282896399497986\n",
      "Step 43100: Train Loss 0.13284990191459656 | Best Val Loss 0.021282896399497986\n",
      "Step 43200: Train Loss 3.3317017555236816 | Best Val Loss 0.021282896399497986\n",
      "Step 43300: Train Loss 0.7001334428787231 | Best Val Loss 0.021282896399497986\n",
      "Step 43400: Train Loss 3.4129316806793213 | Best Val Loss 0.021282896399497986\n",
      "Step 43500: Train Loss 0.6138182282447815 | Best Val Loss 0.021282896399497986\n",
      "Step 43600: Train Loss 0.3083491921424866 | Best Val Loss 0.021282896399497986\n",
      "Step 43700: Train Loss 29.295391082763672 | Best Val Loss 0.021282896399497986\n",
      "Step 43800: Train Loss 0.34710928797721863 | Best Val Loss 0.021282896399497986\n",
      "Step 43900: Train Loss 5.123844623565674 | Best Val Loss 0.021282896399497986\n",
      "Step 44000: Validation Loss 1.2705280780792236\n",
      "Step 44000: Train Loss 0.7850896120071411 | Best Val Loss 0.021282896399497986\n",
      "Step 44100: Train Loss 0.552106499671936 | Best Val Loss 0.021282896399497986\n",
      "Step 44200: Train Loss 0.3085651099681854 | Best Val Loss 0.021282896399497986\n",
      "Step 44300: Train Loss 0.23060797154903412 | Best Val Loss 0.021282896399497986\n",
      "Step 44400: Train Loss 0.2790966033935547 | Best Val Loss 0.021282896399497986\n",
      "Step 44500: Train Loss 0.15329673886299133 | Best Val Loss 0.021282896399497986\n",
      "Step 44600: Train Loss 9.53780746459961 | Best Val Loss 0.021282896399497986\n",
      "Step 44700: Train Loss 2.044358968734741 | Best Val Loss 0.021282896399497986\n",
      "Step 44800: Train Loss 2.5760083198547363 | Best Val Loss 0.021282896399497986\n",
      "Step 44900: Train Loss 1.05372953414917 | Best Val Loss 0.021282896399497986\n",
      "Step 45000: Validation Loss 0.76675945520401\n",
      "Step 45000: Train Loss 0.6549041271209717 | Best Val Loss 0.021282896399497986\n",
      "Step 45100: Train Loss 0.3789767622947693 | Best Val Loss 0.021282896399497986\n",
      "Step 45200: Train Loss 0.4696456789970398 | Best Val Loss 0.021282896399497986\n",
      "Step 45300: Train Loss 0.33232003450393677 | Best Val Loss 0.021282896399497986\n",
      "Step 45400: Train Loss 0.1944563388824463 | Best Val Loss 0.021282896399497986\n",
      "Step 45500: Train Loss 0.1268903762102127 | Best Val Loss 0.021282896399497986\n",
      "Step 45600: Train Loss 0.0894724503159523 | Best Val Loss 0.021282896399497986\n",
      "Step 45700: Train Loss 0.06466728448867798 | Best Val Loss 0.021282896399497986\n",
      "Step 45800: Train Loss 0.06235659122467041 | Best Val Loss 0.021282896399497986\n",
      "Step 45900: Train Loss 0.07046350836753845 | Best Val Loss 0.021282896399497986\n",
      "Step 46000: Validation Loss 0.06477479636669159\n",
      "Step 46000: Train Loss 0.04279261454939842 | Best Val Loss 0.021282896399497986\n",
      "Step 46100: Train Loss 0.04484965652227402 | Best Val Loss 0.021282896399497986\n",
      "Step 46200: Train Loss 0.1227836161851883 | Best Val Loss 0.021282896399497986\n",
      "Step 46300: Train Loss 0.05493296682834625 | Best Val Loss 0.021282896399497986\n",
      "Step 46400: Train Loss 0.047134045511484146 | Best Val Loss 0.021282896399497986\n",
      "Step 46500: Train Loss 0.030200419947504997 | Best Val Loss 0.021282896399497986\n",
      "Step 46600: Train Loss 0.02748868055641651 | Best Val Loss 0.021282896399497986\n",
      "Step 46700: Train Loss 0.18853574991226196 | Best Val Loss 0.021282896399497986\n",
      "Step 46800: Train Loss 0.1609455794095993 | Best Val Loss 0.021282896399497986\n",
      "Step 46900: Train Loss 0.07419814169406891 | Best Val Loss 0.021282896399497986\n",
      "Step 47000: Validation Loss 0.0918416753411293\n",
      "Step 47000: Train Loss 0.066250741481781 | Best Val Loss 0.021282896399497986\n",
      "Step 47100: Train Loss 0.04832649976015091 | Best Val Loss 0.021282896399497986\n",
      "Step 47200: Train Loss 0.06908935308456421 | Best Val Loss 0.021282896399497986\n",
      "Step 47300: Train Loss 0.04331517964601517 | Best Val Loss 0.021282896399497986\n",
      "Step 47400: Train Loss 0.1713278889656067 | Best Val Loss 0.021282896399497986\n",
      "Step 47500: Train Loss 0.2298887073993683 | Best Val Loss 0.021282896399497986\n",
      "Step 47600: Train Loss 0.07461346685886383 | Best Val Loss 0.021282896399497986\n",
      "Step 47700: Train Loss 0.07973537594079971 | Best Val Loss 0.021282896399497986\n",
      "Step 47800: Train Loss 0.06373695284128189 | Best Val Loss 0.021282896399497986\n",
      "Step 47900: Train Loss 0.049505479633808136 | Best Val Loss 0.021282896399497986\n",
      "Step 48000: Validation Loss 0.06044849008321762\n",
      "Step 48000: Train Loss 0.05638890340924263 | Best Val Loss 0.021282896399497986\n",
      "Step 48100: Train Loss 0.0417402908205986 | Best Val Loss 0.021282896399497986\n",
      "Step 48200: Train Loss 0.03888378664851189 | Best Val Loss 0.021282896399497986\n",
      "Step 48300: Train Loss 0.03129638731479645 | Best Val Loss 0.021282896399497986\n",
      "Step 48400: Train Loss 0.037307582795619965 | Best Val Loss 0.021282896399497986\n",
      "Step 48500: Train Loss 0.027039669454097748 | Best Val Loss 0.021282896399497986\n",
      "Step 48600: Train Loss 0.02959640696644783 | Best Val Loss 0.021282896399497986\n",
      "Step 48700: Train Loss 0.023503484204411507 | Best Val Loss 0.021282896399497986\n",
      "Step 48800: Train Loss 0.022260602563619614 | Best Val Loss 0.021282896399497986\n",
      "Step 48900: Train Loss 0.03112672083079815 | Best Val Loss 0.021282896399497986\n",
      "Step 49000: Validation Loss 0.0394669733941555\n",
      "Step 49000: Train Loss 0.024358587339520454 | Best Val Loss 0.021282896399497986\n",
      "Step 49100: Train Loss 0.02015036903321743 | Best Val Loss 0.021282896399497986\n",
      "Step 49200: Train Loss 0.024578655138611794 | Best Val Loss 0.021282896399497986\n",
      "Step 49300: Train Loss 0.021634582430124283 | Best Val Loss 0.021282896399497986\n",
      "Step 49400: Train Loss 0.020481102168560028 | Best Val Loss 0.021282896399497986\n",
      "Step 49500: Train Loss 0.11827842891216278 | Best Val Loss 0.021282896399497986\n",
      "Step 49600: Train Loss 0.07104966044425964 | Best Val Loss 0.021282896399497986\n",
      "Step 49700: Train Loss 0.06210215389728546 | Best Val Loss 0.021282896399497986\n",
      "Step 49800: Train Loss 0.03443356603384018 | Best Val Loss 0.021282896399497986\n",
      "Step 49900: Train Loss 0.03152468800544739 | Best Val Loss 0.021282896399497986\n",
      "Step 50000: Validation Loss 0.04226836562156677\n",
      "Step 50000: Train Loss 0.02497430518269539 | Best Val Loss 0.021282896399497986\n",
      "Step 50100: Train Loss 0.023292332887649536 | Best Val Loss 0.021282896399497986\n",
      "Step 50200: Train Loss 0.016610844060778618 | Best Val Loss 0.021282896399497986\n",
      "Step 50300: Train Loss 0.015654005110263824 | Best Val Loss 0.021282896399497986\n",
      "Step 50400: Train Loss 0.013103884644806385 | Best Val Loss 0.021282896399497986\n",
      "Step 50500: Train Loss 0.01646980084478855 | Best Val Loss 0.021282896399497986\n",
      "Step 50600: Train Loss 0.047962166368961334 | Best Val Loss 0.021282896399497986\n",
      "Step 50700: Train Loss 0.0836462527513504 | Best Val Loss 0.021282896399497986\n",
      "Step 50800: Train Loss 0.04626872390508652 | Best Val Loss 0.021282896399497986\n",
      "Step 50900: Train Loss 0.04287654906511307 | Best Val Loss 0.021282896399497986\n",
      "Step 51000: Validation Loss 0.04802137613296509\n",
      "Step 51000: Train Loss 0.031070834025740623 | Best Val Loss 0.021282896399497986\n",
      "Step 51100: Train Loss 0.023141754791140556 | Best Val Loss 0.021282896399497986\n",
      "Step 51200: Train Loss 0.019477706402540207 | Best Val Loss 0.021282896399497986\n",
      "Step 51300: Train Loss 0.015420615673065186 | Best Val Loss 0.021282896399497986\n",
      "Step 51400: Train Loss 0.014643792062997818 | Best Val Loss 0.021282896399497986\n",
      "Step 51500: Train Loss 0.013248082250356674 | Best Val Loss 0.021282896399497986\n",
      "Step 51600: Train Loss 0.012673466466367245 | Best Val Loss 0.021282896399497986\n",
      "Step 51700: Train Loss 0.013457505032420158 | Best Val Loss 0.021282896399497986\n",
      "Step 51800: Train Loss 0.013936745934188366 | Best Val Loss 0.021282896399497986\n",
      "Step 51900: Train Loss 0.009875823743641376 | Best Val Loss 0.021282896399497986\n",
      "Step 52000: Validation Loss 0.02511010505259037\n",
      "Step 52000: Train Loss 0.010875232517719269 | Best Val Loss 0.021282896399497986\n",
      "Step 52100: Train Loss 0.009299689903855324 | Best Val Loss 0.021282896399497986\n",
      "Step 52200: Train Loss 0.010709015652537346 | Best Val Loss 0.021282896399497986\n",
      "Step 52300: Train Loss 0.019355816766619682 | Best Val Loss 0.021282896399497986\n",
      "Step 52400: Train Loss 0.020053613930940628 | Best Val Loss 0.021282896399497986\n",
      "Step 52500: Train Loss 0.012803265824913979 | Best Val Loss 0.021282896399497986\n",
      "Step 52600: Train Loss 0.01685556210577488 | Best Val Loss 0.021282896399497986\n",
      "Step 52700: Train Loss 0.016867514699697495 | Best Val Loss 0.021282896399497986\n",
      "Step 52800: Train Loss 0.01053193025290966 | Best Val Loss 0.021282896399497986\n",
      "Step 52900: Train Loss 0.038885243237018585 | Best Val Loss 0.021282896399497986\n",
      "Step 53000: Validation Loss 0.11367978900671005\n",
      "Step 53000: Train Loss 0.0855456218123436 | Best Val Loss 0.021282896399497986\n",
      "Step 53100: Train Loss 0.08304468542337418 | Best Val Loss 0.021282896399497986\n",
      "Step 53200: Train Loss 0.5866535902023315 | Best Val Loss 0.021282896399497986\n",
      "Step 53300: Train Loss 0.15668803453445435 | Best Val Loss 0.021282896399497986\n",
      "Step 53400: Train Loss 0.07441433519124985 | Best Val Loss 0.021282896399497986\n",
      "Step 53500: Train Loss 0.10942410677671432 | Best Val Loss 0.021282896399497986\n",
      "Step 53600: Train Loss 0.035686761140823364 | Best Val Loss 0.021282896399497986\n",
      "Step 53700: Train Loss 0.0239423718303442 | Best Val Loss 0.021282896399497986\n",
      "Step 53800: Train Loss 0.02470964938402176 | Best Val Loss 0.021282896399497986\n",
      "Step 53900: Train Loss 0.01740812323987484 | Best Val Loss 0.021282896399497986\n",
      "Step 54000: Validation Loss 0.034612275660037994\n",
      "Step 54000: Train Loss 0.013712109997868538 | Best Val Loss 0.021282896399497986\n",
      "Step 54100: Train Loss 0.010952889919281006 | Best Val Loss 0.021282896399497986\n",
      "Step 54200: Train Loss 0.016866015270352364 | Best Val Loss 0.021282896399497986\n",
      "Step 54300: Train Loss 0.024492725729942322 | Best Val Loss 0.021282896399497986\n",
      "Step 54400: Train Loss 0.00967034325003624 | Best Val Loss 0.021282896399497986\n",
      "Step 54500: Train Loss 0.008488761261105537 | Best Val Loss 0.021282896399497986\n",
      "Step 54600: Train Loss 0.008921369910240173 | Best Val Loss 0.021282896399497986\n",
      "Step 54700: Train Loss 0.2437780201435089 | Best Val Loss 0.021282896399497986\n",
      "Step 54800: Train Loss 0.06461620330810547 | Best Val Loss 0.021282896399497986\n",
      "Step 54900: Train Loss 0.03486704081296921 | Best Val Loss 0.021282896399497986\n",
      "Step 55000: Validation Loss 0.05567927286028862\n",
      "Step 55000: Train Loss 0.019272826611995697 | Best Val Loss 0.021282896399497986\n",
      "Step 55100: Train Loss 0.06691128015518188 | Best Val Loss 0.021282896399497986\n",
      "Step 55200: Train Loss 0.017637021839618683 | Best Val Loss 0.021282896399497986\n",
      "Step 55300: Train Loss 0.1409817934036255 | Best Val Loss 0.021282896399497986\n",
      "Step 55400: Train Loss 0.027933413162827492 | Best Val Loss 0.021282896399497986\n",
      "Step 55500: Train Loss 0.022374894469976425 | Best Val Loss 0.021282896399497986\n",
      "Step 55600: Train Loss 3.576446533203125 | Best Val Loss 0.021282896399497986\n",
      "Step 55700: Train Loss 0.22113224864006042 | Best Val Loss 0.021282896399497986\n",
      "Step 55800: Train Loss 0.10714422911405563 | Best Val Loss 0.021282896399497986\n",
      "Step 55900: Train Loss 0.1026749461889267 | Best Val Loss 0.021282896399497986\n",
      "Step 56000: Validation Loss 0.07535874843597412\n",
      "Step 56000: Train Loss 0.061343930661678314 | Best Val Loss 0.021282896399497986\n",
      "Step 56100: Train Loss 0.12715435028076172 | Best Val Loss 0.021282896399497986\n",
      "Step 56200: Train Loss 0.04185256361961365 | Best Val Loss 0.021282896399497986\n",
      "Step 56300: Train Loss 0.02757979929447174 | Best Val Loss 0.021282896399497986\n",
      "Step 56400: Train Loss 0.06418504565954208 | Best Val Loss 0.021282896399497986\n",
      "Step 56500: Train Loss 0.022405970841646194 | Best Val Loss 0.021282896399497986\n",
      "Step 56600: Train Loss 0.017596136778593063 | Best Val Loss 0.021282896399497986\n",
      "Step 56700: Train Loss 0.10937869548797607 | Best Val Loss 0.021282896399497986\n",
      "Step 56800: Train Loss 0.03542790561914444 | Best Val Loss 0.021282896399497986\n",
      "Step 56900: Train Loss 0.1527126431465149 | Best Val Loss 0.021282896399497986\n",
      "Step 57000: Validation Loss 0.04205853119492531\n",
      "Step 57000: Train Loss 0.026351910084486008 | Best Val Loss 0.021282896399497986\n",
      "Step 57100: Train Loss 0.020904559642076492 | Best Val Loss 0.021282896399497986\n",
      "Step 57200: Train Loss 1.428306221961975 | Best Val Loss 0.021282896399497986\n",
      "Step 57300: Train Loss 0.18802984058856964 | Best Val Loss 0.021282896399497986\n",
      "Step 57400: Train Loss 0.06886936724185944 | Best Val Loss 0.021282896399497986\n",
      "Step 57500: Train Loss 1.6782513856887817 | Best Val Loss 0.021282896399497986\n",
      "Step 57600: Train Loss 0.38293319940567017 | Best Val Loss 0.021282896399497986\n",
      "Step 57700: Train Loss 0.060670316219329834 | Best Val Loss 0.021282896399497986\n",
      "Step 57800: Train Loss 0.38740408420562744 | Best Val Loss 0.021282896399497986\n",
      "Step 57900: Train Loss 0.05156581103801727 | Best Val Loss 0.021282896399497986\n",
      "Step 58000: Validation Loss 0.04343973472714424\n",
      "Step 58000: Train Loss 0.0356239378452301 | Best Val Loss 0.021282896399497986\n",
      "Step 58100: Train Loss 0.02622511237859726 | Best Val Loss 0.021282896399497986\n",
      "Step 58200: Train Loss 0.06459861993789673 | Best Val Loss 0.021282896399497986\n",
      "Step 58300: Train Loss 0.034339677542448044 | Best Val Loss 0.021282896399497986\n",
      "Step 58400: Train Loss 0.055805034935474396 | Best Val Loss 0.021282896399497986\n",
      "Step 58500: Train Loss 0.03256406635046005 | Best Val Loss 0.021282896399497986\n",
      "Step 58600: Train Loss 0.024301676079630852 | Best Val Loss 0.021282896399497986\n",
      "Step 58700: Train Loss 0.01784393936395645 | Best Val Loss 0.021282896399497986\n",
      "Step 58800: Train Loss 0.014335747808218002 | Best Val Loss 0.021282896399497986\n",
      "Step 58900: Train Loss 1.128337025642395 | Best Val Loss 0.021282896399497986\n",
      "Step 59000: Validation Loss 0.11844503879547119\n",
      "Step 59000: Train Loss 0.08875001221895218 | Best Val Loss 0.021282896399497986\n",
      "Step 59100: Train Loss 2.1320316791534424 | Best Val Loss 0.021282896399497986\n",
      "Step 59200: Train Loss 0.09021402895450592 | Best Val Loss 0.021282896399497986\n",
      "Step 59300: Train Loss 0.0582188218832016 | Best Val Loss 0.021282896399497986\n",
      "Step 59400: Train Loss 0.1450171172618866 | Best Val Loss 0.021282896399497986\n",
      "Step 59500: Train Loss 0.04919852316379547 | Best Val Loss 0.021282896399497986\n",
      "Step 59600: Train Loss 0.030195629224181175 | Best Val Loss 0.021282896399497986\n",
      "Step 59700: Train Loss 0.033547885715961456 | Best Val Loss 0.021282896399497986\n",
      "Step 59800: Train Loss 0.23133277893066406 | Best Val Loss 0.021282896399497986\n",
      "Step 59900: Train Loss 0.030160626396536827 | Best Val Loss 0.021282896399497986\n",
      "Step 60000: Validation Loss 0.10275810956954956\n",
      "Step 60000: Train Loss 0.019693560898303986 | Best Val Loss 0.021282896399497986\n",
      "Step 60100: Train Loss 0.019581342115998268 | Best Val Loss 0.021282896399497986\n",
      "Step 60200: Train Loss 0.028722142800688744 | Best Val Loss 0.021282896399497986\n",
      "Step 60300: Train Loss 0.02384808100759983 | Best Val Loss 0.021282896399497986\n",
      "Step 60400: Train Loss 0.017587989568710327 | Best Val Loss 0.021282896399497986\n",
      "Step 60500: Train Loss 0.09863466024398804 | Best Val Loss 0.021282896399497986\n",
      "Step 60600: Train Loss 0.34348833560943604 | Best Val Loss 0.021282896399497986\n",
      "Step 60700: Train Loss 0.08508569002151489 | Best Val Loss 0.021282896399497986\n",
      "Step 60800: Train Loss 0.09307372570037842 | Best Val Loss 0.021282896399497986\n",
      "Step 60900: Train Loss 43.43339538574219 | Best Val Loss 0.021282896399497986\n",
      "Step 61000: Validation Loss 0.840726375579834\n",
      "Step 61000: Train Loss 0.6367092132568359 | Best Val Loss 0.021282896399497986\n",
      "Step 61100: Train Loss 0.28797733783721924 | Best Val Loss 0.021282896399497986\n",
      "Step 61200: Train Loss 0.22091445326805115 | Best Val Loss 0.021282896399497986\n",
      "Step 61300: Train Loss 0.14881500601768494 | Best Val Loss 0.021282896399497986\n",
      "Step 61400: Train Loss 0.134214848279953 | Best Val Loss 0.021282896399497986\n",
      "Step 61500: Train Loss 0.1124996542930603 | Best Val Loss 0.021282896399497986\n",
      "Step 61600: Train Loss 0.11739502102136612 | Best Val Loss 0.021282896399497986\n",
      "Step 61700: Train Loss 0.11067333817481995 | Best Val Loss 0.021282896399497986\n",
      "Step 61800: Train Loss 66.61061096191406 | Best Val Loss 0.021282896399497986\n",
      "Step 61900: Train Loss 2.130439043045044 | Best Val Loss 0.021282896399497986\n",
      "Step 62000: Validation Loss 1.7855110168457031\n",
      "Step 62000: Train Loss 1.202963948249817 | Best Val Loss 0.021282896399497986\n",
      "Step 62100: Train Loss 0.5045108795166016 | Best Val Loss 0.021282896399497986\n",
      "Step 62200: Train Loss 0.3081709146499634 | Best Val Loss 0.021282896399497986\n",
      "Step 62300: Train Loss 0.6551607847213745 | Best Val Loss 0.021282896399497986\n",
      "Step 62400: Train Loss 0.11667501926422119 | Best Val Loss 0.021282896399497986\n",
      "Step 62500: Train Loss 0.09721539914608002 | Best Val Loss 0.021282896399497986\n",
      "Step 62600: Train Loss 0.05680326372385025 | Best Val Loss 0.021282896399497986\n",
      "Step 62700: Train Loss 0.6484181880950928 | Best Val Loss 0.021282896399497986\n",
      "Step 62800: Train Loss 0.2570185363292694 | Best Val Loss 0.021282896399497986\n",
      "Step 62900: Train Loss 0.137486532330513 | Best Val Loss 0.021282896399497986\n",
      "Step 63000: Validation Loss 0.13930641114711761\n",
      "Step 63000: Train Loss 0.11370530724525452 | Best Val Loss 0.021282896399497986\n",
      "Step 63100: Train Loss 0.08718419075012207 | Best Val Loss 0.021282896399497986\n",
      "Step 63200: Train Loss 0.055349983274936676 | Best Val Loss 0.021282896399497986\n",
      "Step 63300: Train Loss 0.05446504056453705 | Best Val Loss 0.021282896399497986\n",
      "Step 63400: Train Loss 2.480853319168091 | Best Val Loss 0.021282896399497986\n",
      "Step 63500: Train Loss 0.37803977727890015 | Best Val Loss 0.021282896399497986\n",
      "Step 63600: Train Loss 0.12169119715690613 | Best Val Loss 0.021282896399497986\n",
      "Step 63700: Train Loss 0.08298005163669586 | Best Val Loss 0.021282896399497986\n",
      "Step 63800: Train Loss 0.0631045252084732 | Best Val Loss 0.021282896399497986\n",
      "Step 63900: Train Loss 8.56876277923584 | Best Val Loss 0.021282896399497986\n",
      "Step 64000: Validation Loss 7.2456440925598145\n",
      "Step 64000: Train Loss 5.855978965759277 | Best Val Loss 0.021282896399497986\n",
      "Step 64100: Train Loss 0.2675705552101135 | Best Val Loss 0.021282896399497986\n",
      "Step 64200: Train Loss 0.1654091477394104 | Best Val Loss 0.021282896399497986\n",
      "Step 64300: Train Loss 0.14735591411590576 | Best Val Loss 0.021282896399497986\n",
      "Step 64400: Train Loss 1.477763295173645 | Best Val Loss 0.021282896399497986\n",
      "Step 64500: Train Loss 5.436549186706543 | Best Val Loss 0.021282896399497986\n",
      "Step 64600: Train Loss 1.9427831172943115 | Best Val Loss 0.021282896399497986\n",
      "Step 64700: Train Loss 0.44966283440589905 | Best Val Loss 0.021282896399497986\n",
      "Step 64800: Train Loss 0.27068740129470825 | Best Val Loss 0.021282896399497986\n",
      "Step 64900: Train Loss 0.2290828824043274 | Best Val Loss 0.021282896399497986\n",
      "Step 65000: Validation Loss 0.117414191365242\n",
      "Step 65000: Train Loss 0.08980339765548706 | Best Val Loss 0.021282896399497986\n",
      "Step 65100: Train Loss 0.06866280734539032 | Best Val Loss 0.021282896399497986\n",
      "Step 65200: Train Loss 0.0692531019449234 | Best Val Loss 0.021282896399497986\n",
      "Step 65300: Train Loss 0.08920088410377502 | Best Val Loss 0.021282896399497986\n",
      "Step 65400: Train Loss 0.04068433865904808 | Best Val Loss 0.021282896399497986\n",
      "Step 65500: Train Loss 0.039769671857357025 | Best Val Loss 0.021282896399497986\n",
      "Step 65600: Train Loss 0.03600429370999336 | Best Val Loss 0.021282896399497986\n",
      "Step 65700: Train Loss 0.08969055861234665 | Best Val Loss 0.021282896399497986\n",
      "Step 65800: Train Loss 13.086808204650879 | Best Val Loss 0.021282896399497986\n",
      "Step 65900: Train Loss 0.025591649115085602 | Best Val Loss 0.021282896399497986\n",
      "Step 66000: Validation Loss 0.0465845949947834\n",
      "Step 66000: Train Loss 0.02441016212105751 | Best Val Loss 0.021282896399497986\n",
      "Step 66100: Train Loss 0.8610244393348694 | Best Val Loss 0.021282896399497986\n",
      "Step 66200: Train Loss 0.37721049785614014 | Best Val Loss 0.021282896399497986\n",
      "Step 66300: Train Loss 8.955692291259766 | Best Val Loss 0.021282896399497986\n",
      "Step 66400: Train Loss 0.5767207145690918 | Best Val Loss 0.021282896399497986\n",
      "Step 66500: Train Loss 22.15391731262207 | Best Val Loss 0.021282896399497986\n",
      "Step 66600: Train Loss 1.710439920425415 | Best Val Loss 0.021282896399497986\n",
      "Step 66700: Train Loss 0.34805795550346375 | Best Val Loss 0.021282896399497986\n",
      "Step 66800: Train Loss 0.21468505263328552 | Best Val Loss 0.021282896399497986\n",
      "Step 66900: Train Loss 0.09643332660198212 | Best Val Loss 0.021282896399497986\n",
      "Step 67000: Validation Loss 0.6049179434776306\n",
      "Step 67000: Train Loss 0.5936481952667236 | Best Val Loss 0.021282896399497986\n",
      "Step 67100: Train Loss 0.08755022287368774 | Best Val Loss 0.021282896399497986\n",
      "Step 67200: Train Loss 0.10052657127380371 | Best Val Loss 0.021282896399497986\n",
      "Step 67300: Train Loss 0.06275862455368042 | Best Val Loss 0.021282896399497986\n",
      "Step 67400: Train Loss 1.6118810176849365 | Best Val Loss 0.021282896399497986\n",
      "Step 67500: Train Loss 0.3210935592651367 | Best Val Loss 0.021282896399497986\n",
      "Step 67600: Train Loss 0.22077816724777222 | Best Val Loss 0.021282896399497986\n",
      "Step 67700: Train Loss 0.09905664622783661 | Best Val Loss 0.021282896399497986\n",
      "Step 67800: Train Loss 0.1024029403924942 | Best Val Loss 0.021282896399497986\n",
      "Step 67900: Train Loss 0.10579098761081696 | Best Val Loss 0.021282896399497986\n",
      "Step 68000: Validation Loss 0.2832864820957184\n",
      "Step 68000: Train Loss 0.16456004977226257 | Best Val Loss 0.021282896399497986\n",
      "Step 68100: Train Loss 0.13925936818122864 | Best Val Loss 0.021282896399497986\n",
      "Step 68200: Train Loss 0.12316417694091797 | Best Val Loss 0.021282896399497986\n",
      "Step 68300: Train Loss 0.08169161528348923 | Best Val Loss 0.021282896399497986\n",
      "Step 68400: Train Loss 0.04161309823393822 | Best Val Loss 0.021282896399497986\n",
      "Step 68500: Train Loss 0.0694701224565506 | Best Val Loss 0.021282896399497986\n",
      "Step 68600: Train Loss 0.5367439985275269 | Best Val Loss 0.021282896399497986\n",
      "Step 68700: Train Loss 0.2658921182155609 | Best Val Loss 0.021282896399497986\n",
      "Step 68800: Train Loss 0.0739213079214096 | Best Val Loss 0.021282896399497986\n",
      "Step 68900: Train Loss 45.5939826965332 | Best Val Loss 0.021282896399497986\n",
      "Step 69000: Validation Loss 0.057583242654800415\n",
      "Step 69000: Train Loss 0.04073864966630936 | Best Val Loss 0.021282896399497986\n",
      "Step 69100: Train Loss 0.0245559923350811 | Best Val Loss 0.021282896399497986\n",
      "Step 69200: Train Loss 0.0285232812166214 | Best Val Loss 0.021282896399497986\n",
      "Step 69300: Train Loss 0.13492651283740997 | Best Val Loss 0.021282896399497986\n",
      "Step 69400: Train Loss 0.10704585909843445 | Best Val Loss 0.021282896399497986\n",
      "Step 69500: Train Loss 0.03606175631284714 | Best Val Loss 0.021282896399497986\n",
      "Step 69600: Train Loss 0.01958327367901802 | Best Val Loss 0.021282896399497986\n",
      "Step 69700: Train Loss 0.6206272840499878 | Best Val Loss 0.021282896399497986\n",
      "Step 69800: Train Loss 0.01664368435740471 | Best Val Loss 0.021282896399497986\n",
      "Step 69900: Train Loss 0.014253457076847553 | Best Val Loss 0.021282896399497986\n",
      "Step 70000: Validation Loss 0.02813626267015934\n",
      "Step 70000: Train Loss 0.013825852423906326 | Best Val Loss 0.021282896399497986\n",
      "Step 70100: Train Loss 0.011305252090096474 | Best Val Loss 0.021282896399497986\n",
      "Step 70200: Train Loss 0.010946793481707573 | Best Val Loss 0.021282896399497986\n",
      "Step 70300: Train Loss 0.0748690813779831 | Best Val Loss 0.021282896399497986\n",
      "Step 70400: Train Loss 0.04168673977255821 | Best Val Loss 0.021282896399497986\n",
      "Step 70500: Train Loss 0.02788742631673813 | Best Val Loss 0.021282896399497986\n",
      "Step 70600: Train Loss 0.029106220230460167 | Best Val Loss 0.021282896399497986\n",
      "Step 70700: Train Loss 0.03896104544401169 | Best Val Loss 0.021282896399497986\n",
      "Step 70800: Train Loss 0.018388068303465843 | Best Val Loss 0.021282896399497986\n",
      "Step 70900: Train Loss 0.02909266948699951 | Best Val Loss 0.021282896399497986\n",
      "Step 71000: Validation Loss 0.03272577002644539\n",
      "Step 71000: Train Loss 0.018308671191334724 | Best Val Loss 0.021282896399497986\n",
      "Step 71100: Train Loss 0.016424600034952164 | Best Val Loss 0.021282896399497986\n",
      "Step 71200: Train Loss 0.016030721366405487 | Best Val Loss 0.021282896399497986\n",
      "Step 71300: Train Loss 0.020519066601991653 | Best Val Loss 0.021282896399497986\n",
      "Step 71400: Train Loss 0.01867573708295822 | Best Val Loss 0.021282896399497986\n",
      "Step 71500: Train Loss 0.016816046088933945 | Best Val Loss 0.021282896399497986\n",
      "Step 71600: Train Loss 0.02012789621949196 | Best Val Loss 0.021282896399497986\n",
      "Step 71700: Train Loss 0.012506161816418171 | Best Val Loss 0.021282896399497986\n",
      "Step 71800: Train Loss 0.10637867450714111 | Best Val Loss 0.021282896399497986\n",
      "Step 71900: Train Loss 0.07893849164247513 | Best Val Loss 0.021282896399497986\n",
      "Step 72000: Validation Loss 0.04659528285264969\n",
      "Step 72000: Train Loss 0.03037836402654648 | Best Val Loss 0.021282896399497986\n",
      "Step 72100: Train Loss 0.025171615183353424 | Best Val Loss 0.021282896399497986\n",
      "Step 72200: Train Loss 0.0234806127846241 | Best Val Loss 0.021282896399497986\n",
      "Step 72300: Train Loss 0.016590993851423264 | Best Val Loss 0.021282896399497986\n",
      "Step 72400: Train Loss 0.018584107980132103 | Best Val Loss 0.021282896399497986\n",
      "Step 72500: Train Loss 0.02657921239733696 | Best Val Loss 0.021282896399497986\n",
      "Step 72600: Train Loss 0.00906828511506319 | Best Val Loss 0.021282896399497986\n",
      "Step 72700: Train Loss 0.15750598907470703 | Best Val Loss 0.021282896399497986\n",
      "Step 72800: Train Loss 0.014736737124621868 | Best Val Loss 0.021282896399497986\n",
      "Step 72900: Train Loss 0.00942818820476532 | Best Val Loss 0.021282896399497986\n",
      "Step 73000: Validation Loss 0.1842435896396637\n",
      "Step 73000: Train Loss 0.1257701963186264 | Best Val Loss 0.021282896399497986\n",
      "Step 73100: Train Loss 0.14524058997631073 | Best Val Loss 0.021282896399497986\n",
      "Step 73200: Train Loss 0.014722646214067936 | Best Val Loss 0.021282896399497986\n",
      "Step 73300: Train Loss 0.010677742771804333 | Best Val Loss 0.021282896399497986\n",
      "Step 73400: Train Loss 0.030964773148298264 | Best Val Loss 0.021282896399497986\n",
      "Step 73500: Train Loss 0.016666360199451447 | Best Val Loss 0.021282896399497986\n",
      "Step 73600: Train Loss 0.013065424747765064 | Best Val Loss 0.021282896399497986\n",
      "Step 73700: Train Loss 0.030511867254972458 | Best Val Loss 0.021282896399497986\n",
      "Step 73800: Train Loss 0.8883723616600037 | Best Val Loss 0.021282896399497986\n",
      "Step 73900: Train Loss 0.02082875370979309 | Best Val Loss 0.021282896399497986\n",
      "Step 74000: Validation Loss 0.02767159789800644\n",
      "Step 74000: Train Loss 0.014879782684147358 | Best Val Loss 0.021282896399497986\n",
      "Step 74100: Train Loss 0.010415407828986645 | Best Val Loss 0.021282896399497986\n",
      "Step 74200: Train Loss 4.438765048980713 | Best Val Loss 0.021282896399497986\n",
      "Step 74300: Train Loss 0.1343306303024292 | Best Val Loss 0.021282896399497986\n",
      "Step 74400: Train Loss 0.028706613928079605 | Best Val Loss 0.021282896399497986\n",
      "Step 74500: Train Loss 0.09217886626720428 | Best Val Loss 0.021282896399497986\n",
      "Step 74600: Train Loss 0.02912272699177265 | Best Val Loss 0.021282896399497986\n",
      "Step 74700: Train Loss 0.015538162551820278 | Best Val Loss 0.021282896399497986\n",
      "Step 74800: Train Loss 0.012681503780186176 | Best Val Loss 0.021282896399497986\n",
      "Step 74900: Train Loss 0.009003689512610435 | Best Val Loss 0.021282896399497986\n",
      "Step 75000: Validation Loss 0.07082517445087433\n",
      "Step 75000: Train Loss 0.04362667351961136 | Best Val Loss 0.021282896399497986\n",
      "Step 75100: Train Loss 0.17356398701667786 | Best Val Loss 0.021282896399497986\n",
      "Step 75200: Train Loss 0.12351009994745255 | Best Val Loss 0.021282896399497986\n",
      "Step 75300: Train Loss 0.1115640327334404 | Best Val Loss 0.021282896399497986\n",
      "Step 75400: Train Loss 0.05330715700984001 | Best Val Loss 0.021282896399497986\n",
      "Step 75500: Train Loss 0.011421632021665573 | Best Val Loss 0.021282896399497986\n",
      "Step 75600: Train Loss 0.00999366957694292 | Best Val Loss 0.021282896399497986\n",
      "Step 75700: Train Loss 0.01264452375471592 | Best Val Loss 0.021282896399497986\n",
      "Step 75800: Train Loss 0.03871215507388115 | Best Val Loss 0.021282896399497986\n",
      "Step 75900: Train Loss 0.023533497005701065 | Best Val Loss 0.021282896399497986\n",
      "Step 76000: Validation Loss 0.03800405561923981\n",
      "Step 76000: Train Loss 0.02489018440246582 | Best Val Loss 0.021282896399497986\n",
      "Step 76100: Train Loss 0.6679816246032715 | Best Val Loss 0.021282896399497986\n",
      "Step 76200: Train Loss 0.07650576531887054 | Best Val Loss 0.021282896399497986\n",
      "Step 76300: Train Loss 0.26200270652770996 | Best Val Loss 0.021282896399497986\n",
      "Step 76400: Train Loss 0.02364632487297058 | Best Val Loss 0.021282896399497986\n",
      "Step 76500: Train Loss 0.01418250985443592 | Best Val Loss 0.021282896399497986\n",
      "Step 76600: Train Loss 0.013921951875090599 | Best Val Loss 0.021282896399497986\n",
      "Step 76700: Train Loss 0.010103605687618256 | Best Val Loss 0.021282896399497986\n",
      "Step 76800: Train Loss 0.16046351194381714 | Best Val Loss 0.021282896399497986\n",
      "Step 76900: Train Loss 0.010241789743304253 | Best Val Loss 0.021282896399497986\n",
      "Step 77000: Validation Loss 0.028663666918873787\n",
      "Step 77000: Train Loss 0.007756790146231651 | Best Val Loss 0.021282896399497986\n",
      "Step 77100: Train Loss 0.007684101350605488 | Best Val Loss 0.021282896399497986\n",
      "Step 77200: Train Loss 0.007829196751117706 | Best Val Loss 0.021282896399497986\n",
      "Step 77300: Train Loss 0.0048121120780706406 | Best Val Loss 0.021282896399497986\n",
      "Step 77400: Train Loss 0.005652321502566338 | Best Val Loss 0.021282896399497986\n",
      "Step 77500: Train Loss 0.1320592612028122 | Best Val Loss 0.021282896399497986\n",
      "Step 77600: Train Loss 0.015146676450967789 | Best Val Loss 0.021282896399497986\n",
      "Step 77700: Train Loss 0.011680180206894875 | Best Val Loss 0.021282896399497986\n",
      "Step 77800: Train Loss 0.011021208018064499 | Best Val Loss 0.021282896399497986\n",
      "Step 77900: Train Loss 0.06385871767997742 | Best Val Loss 0.021282896399497986\n",
      "Step 78000: Validation Loss 0.052317604422569275\n",
      "Step 78000: Train Loss 0.03400089964270592 | Best Val Loss 0.021282896399497986\n",
      "Step 78100: Train Loss 0.05187495797872543 | Best Val Loss 0.021282896399497986\n",
      "Step 78200: Train Loss 0.021713528782129288 | Best Val Loss 0.021282896399497986\n",
      "Step 78300: Train Loss 0.012394166551530361 | Best Val Loss 0.021282896399497986\n",
      "Step 78400: Train Loss 0.09789206087589264 | Best Val Loss 0.021282896399497986\n",
      "Step 78500: Train Loss 0.02250429056584835 | Best Val Loss 0.021282896399497986\n",
      "Step 78600: Train Loss 0.012722186744213104 | Best Val Loss 0.021282896399497986\n",
      "Step 78700: Train Loss 0.010041512548923492 | Best Val Loss 0.021282896399497986\n",
      "Step 78800: Train Loss 0.00742096733301878 | Best Val Loss 0.021282896399497986\n",
      "Step 78900: Train Loss 0.05856657028198242 | Best Val Loss 0.021282896399497986\n",
      "Step 79000: Validation Loss 0.03412119299173355\n",
      "Step 79000: Train Loss 0.02013784646987915 | Best Val Loss 0.021282896399497986\n",
      "Step 79100: Train Loss 0.04948992282152176 | Best Val Loss 0.021282896399497986\n",
      "Step 79200: Train Loss 0.01990336924791336 | Best Val Loss 0.021282896399497986\n",
      "Step 79300: Train Loss 0.013800621964037418 | Best Val Loss 0.021282896399497986\n",
      "Step 79400: Train Loss 0.009676462039351463 | Best Val Loss 0.021282896399497986\n",
      "Step 79500: Train Loss 0.012229000218212605 | Best Val Loss 0.021282896399497986\n",
      "Step 79600: Train Loss 0.0286225788295269 | Best Val Loss 0.021282896399497986\n",
      "Step 79700: Train Loss 0.04130521044135094 | Best Val Loss 0.021282896399497986\n",
      "Step 79800: Train Loss 0.019864056259393692 | Best Val Loss 0.021282896399497986\n",
      "Step 79900: Train Loss 0.012035490944981575 | Best Val Loss 0.021282896399497986\n",
      "Step 80000: Validation Loss 0.14563967287540436\n",
      "Step 80000: Train Loss 0.09285099804401398 | Best Val Loss 0.021282896399497986\n",
      "Step 80100: Train Loss 0.03191713988780975 | Best Val Loss 0.021282896399497986\n",
      "Step 80200: Train Loss 0.01768368110060692 | Best Val Loss 0.021282896399497986\n",
      "Step 80300: Train Loss 0.01429089717566967 | Best Val Loss 0.021282896399497986\n",
      "Step 80400: Train Loss 0.006807650439441204 | Best Val Loss 0.021282896399497986\n",
      "Step 80500: Train Loss 0.04774167388677597 | Best Val Loss 0.021282896399497986\n",
      "Step 80600: Train Loss 0.013458753004670143 | Best Val Loss 0.021282896399497986\n",
      "Step 80700: Train Loss 0.013177945278584957 | Best Val Loss 0.021282896399497986\n",
      "Step 80800: Train Loss 0.007062089629471302 | Best Val Loss 0.021282896399497986\n",
      "Step 80900: Train Loss 0.00634155934676528 | Best Val Loss 0.021282896399497986\n",
      "Step 81000: Validation Loss 0.024944813922047615\n",
      "Step 81000: Train Loss 0.005697199609130621 | Best Val Loss 0.021282896399497986\n",
      "Step 81100: Train Loss 0.004614600446075201 | Best Val Loss 0.021282896399497986\n",
      "Step 81200: Train Loss 0.0063081467524170876 | Best Val Loss 0.021282896399497986\n",
      "Step 81300: Train Loss 0.023448005318641663 | Best Val Loss 0.021282896399497986\n",
      "Step 81400: Train Loss 0.01117384247481823 | Best Val Loss 0.021282896399497986\n",
      "Step 81500: Train Loss 0.02133708819746971 | Best Val Loss 0.021282896399497986\n",
      "Step 81600: Train Loss 0.05441432446241379 | Best Val Loss 0.021282896399497986\n",
      "Step 81700: Train Loss 0.024010471999645233 | Best Val Loss 0.021282896399497986\n",
      "Step 81800: Train Loss 0.017993487417697906 | Best Val Loss 0.021282896399497986\n",
      "Step 81900: Train Loss 0.009497453458607197 | Best Val Loss 0.021282896399497986\n",
      "Step 82000: Validation Loss 0.03324410691857338\n",
      "Step 82000: Train Loss 0.0250076986849308 | Best Val Loss 0.021282896399497986\n",
      "Step 82100: Train Loss 0.020164581015706062 | Best Val Loss 0.021282896399497986\n",
      "Step 82200: Train Loss 0.01787896826863289 | Best Val Loss 0.021282896399497986\n",
      "Step 82300: Train Loss 0.0320163369178772 | Best Val Loss 0.021282896399497986\n",
      "Step 82400: Train Loss 0.012110467068850994 | Best Val Loss 0.021282896399497986\n",
      "Step 82500: Train Loss 0.015054850839078426 | Best Val Loss 0.021282896399497986\n",
      "Step 82600: Train Loss 0.06920195370912552 | Best Val Loss 0.021282896399497986\n",
      "Step 82700: Train Loss 0.03497470170259476 | Best Val Loss 0.021282896399497986\n",
      "Step 82800: Train Loss 0.027535799890756607 | Best Val Loss 0.021282896399497986\n",
      "Step 82900: Train Loss 0.020587943494319916 | Best Val Loss 0.021282896399497986\n",
      "Step 83000: Validation Loss 0.025672242045402527\n",
      "Step 83000: Train Loss 0.012609859928488731 | Best Val Loss 0.021282896399497986\n",
      "Step 83100: Train Loss 0.2575814127922058 | Best Val Loss 0.021282896399497986\n",
      "Step 83200: Train Loss 0.33021149039268494 | Best Val Loss 0.021282896399497986\n",
      "Step 83300: Train Loss 0.0903186947107315 | Best Val Loss 0.021282896399497986\n",
      "Step 83400: Train Loss 0.06533988565206528 | Best Val Loss 0.021282896399497986\n",
      "Step 83500: Train Loss 0.015233480371534824 | Best Val Loss 0.021282896399497986\n",
      "Step 83600: Train Loss 0.010162224993109703 | Best Val Loss 0.021282896399497986\n",
      "Step 83700: Train Loss 0.00939544290304184 | Best Val Loss 0.021282896399497986\n",
      "Step 83800: Train Loss 0.011240864172577858 | Best Val Loss 0.021282896399497986\n",
      "Step 83900: Train Loss 0.15264376997947693 | Best Val Loss 0.021282896399497986\n",
      "Step 84000: Validation Loss 0.053187884390354156\n",
      "Step 84000: Train Loss 0.04320400953292847 | Best Val Loss 0.021282896399497986\n",
      "Step 84100: Train Loss 0.44709083437919617 | Best Val Loss 0.021282896399497986\n",
      "Step 84200: Train Loss 0.024172883480787277 | Best Val Loss 0.021282896399497986\n",
      "Step 84300: Train Loss 106.7647476196289 | Best Val Loss 0.021282896399497986\n",
      "Step 84400: Train Loss 0.8900741338729858 | Best Val Loss 0.021282896399497986\n",
      "Step 84500: Train Loss 8.317867279052734 | Best Val Loss 0.021282896399497986\n",
      "Step 84600: Train Loss 5.264681816101074 | Best Val Loss 0.021282896399497986\n",
      "Step 84700: Train Loss 0.9853729605674744 | Best Val Loss 0.021282896399497986\n",
      "Step 84800: Train Loss 0.32662564516067505 | Best Val Loss 0.021282896399497986\n",
      "Step 84900: Train Loss 5.793392181396484 | Best Val Loss 0.021282896399497986\n",
      "Step 85000: Validation Loss 1.2305647134780884\n",
      "Step 85000: Train Loss 1.087578296661377 | Best Val Loss 0.021282896399497986\n",
      "Step 85100: Train Loss 0.8451639413833618 | Best Val Loss 0.021282896399497986\n",
      "Step 85200: Train Loss 1.619847059249878 | Best Val Loss 0.021282896399497986\n",
      "Step 85300: Train Loss 10.395193099975586 | Best Val Loss 0.021282896399497986\n",
      "Step 85400: Train Loss 1.4065046310424805 | Best Val Loss 0.021282896399497986\n",
      "Step 85500: Train Loss 0.5175747871398926 | Best Val Loss 0.021282896399497986\n",
      "Step 85600: Train Loss 1.3835537433624268 | Best Val Loss 0.021282896399497986\n",
      "Step 85700: Train Loss 0.48027175664901733 | Best Val Loss 0.021282896399497986\n",
      "Step 85800: Train Loss 0.37189173698425293 | Best Val Loss 0.021282896399497986\n",
      "Step 85900: Train Loss 0.2934061884880066 | Best Val Loss 0.021282896399497986\n",
      "Step 86000: Validation Loss 0.1919289529323578\n",
      "Step 86000: Train Loss 0.09915000200271606 | Best Val Loss 0.021282896399497986\n",
      "Step 86100: Train Loss 0.09455208480358124 | Best Val Loss 0.021282896399497986\n",
      "Step 86200: Train Loss 1.1516633033752441 | Best Val Loss 0.021282896399497986\n",
      "Step 86300: Train Loss 0.3989148736000061 | Best Val Loss 0.021282896399497986\n",
      "Step 86400: Train Loss 0.2549893856048584 | Best Val Loss 0.021282896399497986\n",
      "Step 86500: Train Loss 0.17456303536891937 | Best Val Loss 0.021282896399497986\n",
      "Step 86600: Train Loss 0.2825292646884918 | Best Val Loss 0.021282896399497986\n",
      "Step 86700: Train Loss 0.08844694495201111 | Best Val Loss 0.021282896399497986\n",
      "Step 86800: Train Loss 0.04922805726528168 | Best Val Loss 0.021282896399497986\n",
      "Step 86900: Train Loss 0.07437051832675934 | Best Val Loss 0.021282896399497986\n",
      "Step 87000: Validation Loss 1.4531692266464233\n",
      "Step 87000: Train Loss 1.253222942352295 | Best Val Loss 0.021282896399497986\n",
      "Step 87100: Train Loss 1.7868685722351074 | Best Val Loss 0.021282896399497986\n",
      "Step 87200: Train Loss 0.11095428466796875 | Best Val Loss 0.021282896399497986\n",
      "Step 87300: Train Loss 0.09003038704395294 | Best Val Loss 0.021282896399497986\n",
      "Step 87400: Train Loss 0.3320220112800598 | Best Val Loss 0.021282896399497986\n",
      "Step 87500: Train Loss 0.2626034617424011 | Best Val Loss 0.021282896399497986\n",
      "Step 87600: Train Loss 0.05351682007312775 | Best Val Loss 0.021282896399497986\n",
      "Step 87700: Train Loss 0.04672398418188095 | Best Val Loss 0.021282896399497986\n",
      "Step 87800: Train Loss 0.04198054224252701 | Best Val Loss 0.021282896399497986\n",
      "Step 87900: Train Loss 0.06446990370750427 | Best Val Loss 0.021282896399497986\n",
      "Step 88000: Validation Loss 0.06193213909864426\n",
      "Step 88000: Train Loss 0.044949986040592194 | Best Val Loss 0.021282896399497986\n",
      "Step 88100: Train Loss 0.0643642246723175 | Best Val Loss 0.021282896399497986\n",
      "Step 88200: Train Loss 0.04227998107671738 | Best Val Loss 0.021282896399497986\n",
      "Step 88300: Train Loss 0.04282160475850105 | Best Val Loss 0.021282896399497986\n",
      "Step 88400: Train Loss 0.0380583330988884 | Best Val Loss 0.021282896399497986\n",
      "Step 88500: Train Loss 0.031418222934007645 | Best Val Loss 0.021282896399497986\n",
      "Step 88600: Train Loss 0.03051910549402237 | Best Val Loss 0.021282896399497986\n",
      "Step 88700: Train Loss 0.0246804878115654 | Best Val Loss 0.021282896399497986\n",
      "Step 88800: Train Loss 0.032315853983163834 | Best Val Loss 0.021282896399497986\n",
      "Step 88900: Train Loss 0.03438838571310043 | Best Val Loss 0.021282896399497986\n",
      "Step 89000: Validation Loss 0.13564534485340118\n",
      "Step 89000: Train Loss 0.10033959895372391 | Best Val Loss 0.021282896399497986\n",
      "Step 89100: Train Loss 0.03396153822541237 | Best Val Loss 0.021282896399497986\n",
      "Step 89200: Train Loss 0.03832544386386871 | Best Val Loss 0.021282896399497986\n",
      "Step 89300: Train Loss 0.03922966122627258 | Best Val Loss 0.021282896399497986\n",
      "Step 89400: Train Loss 0.031231556087732315 | Best Val Loss 0.021282896399497986\n",
      "Step 89500: Train Loss 0.028972825035452843 | Best Val Loss 0.021282896399497986\n",
      "Step 89600: Train Loss 0.06606438755989075 | Best Val Loss 0.021282896399497986\n",
      "Step 89700: Train Loss 0.0467204675078392 | Best Val Loss 0.021282896399497986\n",
      "Step 89800: Train Loss 0.03916645422577858 | Best Val Loss 0.021282896399497986\n",
      "Step 89900: Train Loss 0.10174541920423508 | Best Val Loss 0.021282896399497986\n",
      "Step 90000: Validation Loss 0.039465710520744324\n",
      "Step 90000: Train Loss 0.026156429201364517 | Best Val Loss 0.021282896399497986\n",
      "Step 90100: Train Loss 0.01937917061150074 | Best Val Loss 0.021282896399497986\n",
      "Step 90200: Train Loss 51.14830780029297 | Best Val Loss 0.021282896399497986\n",
      "Step 90300: Train Loss 0.03282774239778519 | Best Val Loss 0.021282896399497986\n",
      "Step 90400: Train Loss 0.029711734503507614 | Best Val Loss 0.021282896399497986\n",
      "Step 90500: Train Loss 0.03333180025219917 | Best Val Loss 0.021282896399497986\n",
      "Step 90600: Train Loss 0.03157275915145874 | Best Val Loss 0.021282896399497986\n",
      "Step 90700: Train Loss 0.023917172104120255 | Best Val Loss 0.021282896399497986\n",
      "Step 90800: Train Loss 0.024459954351186752 | Best Val Loss 0.021282896399497986\n",
      "Step 90900: Train Loss 0.022984866052865982 | Best Val Loss 0.021282896399497986\n",
      "Step 91000: Validation Loss 0.03757091239094734\n",
      "Step 91000: Train Loss 0.02225188910961151 | Best Val Loss 0.021282896399497986\n",
      "Step 91100: Train Loss 0.024021459743380547 | Best Val Loss 0.021282896399497986\n",
      "Step 91200: Train Loss 0.025683369487524033 | Best Val Loss 0.021282896399497986\n",
      "Step 91300: Train Loss 0.018386729061603546 | Best Val Loss 0.021282896399497986\n",
      "Step 91400: Train Loss 0.021421147510409355 | Best Val Loss 0.021282896399497986\n",
      "Step 91500: Train Loss 0.08005467057228088 | Best Val Loss 0.021282896399497986\n",
      "Step 91600: Train Loss 0.03495703265070915 | Best Val Loss 0.021282896399497986\n",
      "Step 91700: Train Loss 0.0235236007720232 | Best Val Loss 0.021282896399497986\n",
      "Step 91800: Train Loss 0.02256888523697853 | Best Val Loss 0.021282896399497986\n",
      "Step 91900: Train Loss 0.025966329500079155 | Best Val Loss 0.021282896399497986\n",
      "Step 92000: Validation Loss 0.03581872954964638\n",
      "Step 92000: Train Loss 0.02417542226612568 | Best Val Loss 0.021282896399497986\n",
      "Step 92100: Train Loss 0.022452566772699356 | Best Val Loss 0.021282896399497986\n",
      "Step 92200: Train Loss 0.026881922036409378 | Best Val Loss 0.021282896399497986\n",
      "Step 92300: Train Loss 0.01786268688738346 | Best Val Loss 0.021282896399497986\n",
      "Step 92400: Train Loss 0.014857782050967216 | Best Val Loss 0.021282896399497986\n",
      "Step 92500: Train Loss 0.05852722376585007 | Best Val Loss 0.021282896399497986\n",
      "Step 92600: Train Loss 0.034840065985918045 | Best Val Loss 0.021282896399497986\n",
      "Step 92700: Train Loss 0.022288959473371506 | Best Val Loss 0.021282896399497986\n",
      "Step 92800: Train Loss 0.07829432189464569 | Best Val Loss 0.021282896399497986\n",
      "Step 92900: Train Loss 0.018644265830516815 | Best Val Loss 0.021282896399497986\n",
      "Step 93000: Validation Loss 0.1277211755514145\n",
      "Step 93000: Train Loss 0.08839583396911621 | Best Val Loss 0.021282896399497986\n",
      "Step 93100: Train Loss 0.047018781304359436 | Best Val Loss 0.021282896399497986\n",
      "Step 93200: Train Loss 0.018094953149557114 | Best Val Loss 0.021282896399497986\n",
      "Step 93300: Train Loss 0.01957160048186779 | Best Val Loss 0.021282896399497986\n",
      "Step 93400: Train Loss 0.26906856894493103 | Best Val Loss 0.021282896399497986\n",
      "Step 93500: Train Loss 0.060131363570690155 | Best Val Loss 0.021282896399497986\n",
      "Step 93600: Train Loss 0.05010906606912613 | Best Val Loss 0.021282896399497986\n",
      "Step 93700: Train Loss 0.4499555826187134 | Best Val Loss 0.021282896399497986\n",
      "Step 93800: Train Loss 0.08628155291080475 | Best Val Loss 0.021282896399497986\n",
      "Step 93900: Train Loss 0.0564022995531559 | Best Val Loss 0.021282896399497986\n",
      "Step 94000: Validation Loss 0.045851532369852066\n",
      "Step 94000: Train Loss 0.031095240265130997 | Best Val Loss 0.021282896399497986\n",
      "Step 94100: Train Loss 0.02347986213862896 | Best Val Loss 0.021282896399497986\n",
      "Step 94200: Train Loss 0.5209469795227051 | Best Val Loss 0.021282896399497986\n",
      "Step 94300: Train Loss 0.02542654611170292 | Best Val Loss 0.021282896399497986\n",
      "Step 94400: Train Loss 0.015536975115537643 | Best Val Loss 0.021282896399497986\n",
      "Step 94500: Train Loss 0.08005964756011963 | Best Val Loss 0.021282896399497986\n",
      "Step 94600: Train Loss 0.06975455582141876 | Best Val Loss 0.021282896399497986\n",
      "Step 94700: Train Loss 0.039321187883615494 | Best Val Loss 0.021282896399497986\n",
      "Step 94800: Train Loss 0.03330019861459732 | Best Val Loss 0.021282896399497986\n",
      "Step 94900: Train Loss 0.032786257565021515 | Best Val Loss 0.021282896399497986\n",
      "Step 95000: Validation Loss 0.03846017271280289\n",
      "Step 95000: Train Loss 0.02255094051361084 | Best Val Loss 0.021282896399497986\n",
      "Step 95100: Train Loss 0.02576531283557415 | Best Val Loss 0.021282896399497986\n",
      "Step 95200: Train Loss 0.021327583119273186 | Best Val Loss 0.021282896399497986\n",
      "Step 95300: Train Loss 0.11070418357849121 | Best Val Loss 0.021282896399497986\n",
      "Step 95400: Train Loss 0.06253935396671295 | Best Val Loss 0.021282896399497986\n",
      "Step 95500: Train Loss 0.06155736744403839 | Best Val Loss 0.021282896399497986\n",
      "Step 95600: Train Loss 0.0394643172621727 | Best Val Loss 0.021282896399497986\n",
      "Step 95700: Train Loss 0.02922360599040985 | Best Val Loss 0.021282896399497986\n",
      "Step 95800: Train Loss 0.021522557362914085 | Best Val Loss 0.021282896399497986\n",
      "Step 95900: Train Loss 0.018544645980000496 | Best Val Loss 0.021282896399497986\n",
      "Step 96000: Validation Loss 0.03965187817811966\n",
      "Step 96000: Train Loss 0.02424360066652298 | Best Val Loss 0.021282896399497986\n",
      "Step 96100: Train Loss 0.016519833356142044 | Best Val Loss 0.021282896399497986\n",
      "Step 96200: Train Loss 0.012049529701471329 | Best Val Loss 0.021282896399497986\n",
      "Step 96300: Train Loss 0.009793730452656746 | Best Val Loss 0.021282896399497986\n",
      "Step 96400: Train Loss 0.009123343974351883 | Best Val Loss 0.021282896399497986\n",
      "Step 96500: Train Loss 0.0116072166711092 | Best Val Loss 0.021282896399497986\n",
      "Step 96600: Train Loss 0.011217527091503143 | Best Val Loss 0.021282896399497986\n",
      "Step 96700: Train Loss 0.01909303478896618 | Best Val Loss 0.021282896399497986\n",
      "Step 96800: Train Loss 0.016020290553569794 | Best Val Loss 0.021282896399497986\n",
      "Step 96900: Train Loss 0.010915578342974186 | Best Val Loss 0.021282896399497986\n",
      "Step 97000: Validation Loss 0.032919056713581085\n",
      "Step 97000: Train Loss 0.013130789622664452 | Best Val Loss 0.021282896399497986\n",
      "Step 97100: Train Loss 0.01660989224910736 | Best Val Loss 0.021282896399497986\n",
      "Step 97200: Train Loss 0.10593827813863754 | Best Val Loss 0.021282896399497986\n",
      "Step 97300: Train Loss 0.06878840178251266 | Best Val Loss 0.021282896399497986\n",
      "Step 97400: Train Loss 0.0496613010764122 | Best Val Loss 0.021282896399497986\n",
      "Step 97500: Train Loss 0.04273359477519989 | Best Val Loss 0.021282896399497986\n",
      "Step 97600: Train Loss 0.025690428912639618 | Best Val Loss 0.021282896399497986\n",
      "Step 97700: Train Loss 0.01532465685158968 | Best Val Loss 0.021282896399497986\n",
      "Step 97800: Train Loss 0.016428355127573013 | Best Val Loss 0.021282896399497986\n",
      "Step 97900: Train Loss 0.014143131673336029 | Best Val Loss 0.021282896399497986\n",
      "Step 98000: Validation Loss 0.02684098854660988\n",
      "Step 98000: Train Loss 0.009384403005242348 | Best Val Loss 0.021282896399497986\n",
      "Step 98100: Train Loss 0.008671453222632408 | Best Val Loss 0.021282896399497986\n",
      "Step 98200: Train Loss 0.013427231460809708 | Best Val Loss 0.021282896399497986\n",
      "Step 98300: Train Loss 0.0075272382237017155 | Best Val Loss 0.021282896399497986\n",
      "Step 98400: Train Loss 0.011343671940267086 | Best Val Loss 0.021282896399497986\n",
      "Step 98500: Train Loss 1.5254740715026855 | Best Val Loss 0.021282896399497986\n",
      "Step 98600: Train Loss 0.041127774864435196 | Best Val Loss 0.021282896399497986\n",
      "Step 98700: Train Loss 0.9208742380142212 | Best Val Loss 0.021282896399497986\n",
      "Step 98800: Train Loss 0.1071062907576561 | Best Val Loss 0.021282896399497986\n",
      "Step 98900: Train Loss 0.058299772441387177 | Best Val Loss 0.021282896399497986\n",
      "Step 99000: Validation Loss 0.22806210815906525\n",
      "Step 99000: Train Loss 0.15791860222816467 | Best Val Loss 0.021282896399497986\n",
      "Step 99100: Train Loss 0.09232883900403976 | Best Val Loss 0.021282896399497986\n",
      "Step 99200: Train Loss 0.04997074231505394 | Best Val Loss 0.021282896399497986\n",
      "Step 99300: Train Loss 0.0394735261797905 | Best Val Loss 0.021282896399497986\n",
      "Step 99400: Train Loss 0.028042225167155266 | Best Val Loss 0.021282896399497986\n",
      "Step 99500: Train Loss 0.02637779340147972 | Best Val Loss 0.021282896399497986\n",
      "Step 99600: Train Loss 0.022787556052207947 | Best Val Loss 0.021282896399497986\n",
      "Step 99700: Train Loss 0.022759124636650085 | Best Val Loss 0.021282896399497986\n",
      "Step 99800: Train Loss 0.017069168388843536 | Best Val Loss 0.021282896399497986\n",
      "Step 99900: Train Loss 0.018183454871177673 | Best Val Loss 0.021282896399497986\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(num_steps):\n",
    "    optimizer.zero_grad()\n",
    "    Xb, Yb = get_batch(Xtr, Ytr, batch_size)\n",
    "\n",
    "    Xb = Xb.to('cuda')\n",
    "    Yb = Yb.to('cuda')\n",
    "\n",
    "    loss = criterion(model(Xb), Yb)\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        val_loss = criterion(model(Xval.cuda()), Yval.cuda())\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_model_val.pth')\n",
    "\n",
    "        print(f\"Step {i}: Validation Loss {val_loss.item()}\")\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(f'Step {i}: Train Loss {loss.item()} | Best Val Loss {best_val_loss.item()}')\n",
    "        if loss < best_train_loss:\n",
    "            best_train_loss = loss\n",
    "            torch.save(model.state_dict(), 'best_model_train.pth')\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LTVDynamicsModel(\n",
       "  (time_varying_F): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (5): Linear(in_features=128, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('best_model_val.pth', weights_only=True))\n",
    "model.cpu()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = get_data('data/19500.csv')[:100]\n",
    "test_data = test_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors= []\n",
    "\n",
    "alpha = 0.5\n",
    "x0 = torch.from_numpy(test_data[0, None]).float()\n",
    "x0 = (x0 - mean) / std\n",
    "dx = model(x0).detach()\n",
    "# x1 = x1 * std[3] + mean[3]\n",
    "rollout = [x0[0,3] * std[3] + mean[3], (x0[0,3] + dx[0]) * std[3] + mean[3]] # lateral accelerations [x0[0,3], x1[0]] x0[0, 3] * std[3] + mean[3]\n",
    "for t in range(1, test_data.shape[0]-1):\n",
    "    xt = torch.from_numpy(test_data[t, None]).float()\n",
    "    # xt[:, 3] = (1-alpha) * rollout[-1] + alpha * rollout[-2]\n",
    "    xt = (xt - mean) / std\n",
    "    dx = model(xt).detach()\n",
    "    # xt1 = xt1 * std[3] + mean[3]\n",
    "    xt1 = xt[0, 3] + dx[0]\n",
    "    rollout.append(xt1* std[3] + mean[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_rollout(rollout, test_data):\n",
    "  fig, ax = plt.subplots(figsize=(10, 5))\n",
    "  ax.plot(test_data[:, 3], label=\"GT Lat Acc\", alpha=0.5)\n",
    "  ax.plot([latacc for latacc in rollout], label=\"Model\", alpha=0.5)\n",
    "  ax.legend()\n",
    "  ax.set_xlabel(\"Step\")\n",
    "  ax.set_ylabel(\"Lateral Acceleration\")\n",
    "  ax.set_title(\"Rollout\")\n",
    "  plt.show()\n",
    "\n",
    "plot_rollout(rollout, test_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
